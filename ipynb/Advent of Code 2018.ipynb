{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â [Advent of Code 2018](https://adventofcode.com/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of common functions to be used across problems, will add more as a generic use case for each comes up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "cat = ''.join\n",
    "\n",
    "\n",
    "Point = namedtuple('Point', 'x,y')\n",
    "\n",
    "\n",
    "def Input(day):\n",
    "    \"\"\"Fetch the data input from disk.\"\"\"\n",
    "    filename = os.path.join('../data/advent2018/input{}.txt'.format(day))\n",
    "    return open(filename)\n",
    "\n",
    "\n",
    "def hamming_distance(s1, s2):\n",
    "    \"\"\"Number of non equal characters between two strings.\"\"\"\n",
    "    assert len(s1) == len(s2), 'Strings are not equal length'\n",
    "    return sum(\n",
    "        char1 != char2\n",
    "        for char1, char2\n",
    "        in zip(s1, s2)\n",
    "    )\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 1: Chronal Calibration](https://adventofcode.com/2018/day/1)\n",
    "\n",
    "The first part simply requires us to sum the values in a list to apply all the changes from the given delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(initial_data):\n",
    "    res = []\n",
    "    for data in initial_data.readlines():\n",
    "        res.append(int(data))\n",
    "    return res\n",
    "\n",
    "data = parse_input(Input(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second portion requires us to find the first repeated value if we continually sum items in the delta list. A set is ideal here as it's O(1) for membership tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_repeat(deltas):\n",
    "    seen = set([0])\n",
    "    position = 0\n",
    "    \n",
    "    for delta in cycle(deltas):\n",
    "        position += delta\n",
    "        if position in seen:\n",
    "            break\n",
    "        seen.add(position)\n",
    "    return position\n",
    "\n",
    "assert find_first_repeat([7, 7, -2, -7, -4]) == 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75749"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_first_repeat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 2: Inventory Management System](https://adventofcode.com/2018/day/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [line.strip() for line in Input(2).readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6944"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_checksum(data):\n",
    "    num_threes = 0\n",
    "    num_twos = 0\n",
    "    for line in data:\n",
    "        counts = Counter(line)\n",
    "        if 3 in counts.values():\n",
    "            num_threes += 1\n",
    "        if 2 in counts.values():\n",
    "            num_twos += 1\n",
    "        \n",
    "    return num_threes * num_twos\n",
    "\n",
    "\n",
    "test_data = [\n",
    "    \"abcdef\",\n",
    "    \"bababc\",\n",
    "    \"abbcde\",\n",
    "    \"abcccd\",\n",
    "    \"aabcdd\",\n",
    "    \"abcdee\",\n",
    "    \"ababab\",\n",
    "]\n",
    "assert calculate_checksum(test_data) == 12\n",
    "calculate_checksum(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're told that we need to find two strings that have only one character difference between them, this is also known as the the [Hamming Distance](https://en.wikipedia.org/wiki/Hamming_distance). So we're looking for two strings for which the hamming distance bewteen them is one, simple enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'srijafjzloguvlntqmphenbkd'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_boxes(data):\n",
    "    for index, row in enumerate(data[:-1]):\n",
    "        for comparison in data[index:]:\n",
    "            if hamming_distance(row, comparison) == 1:\n",
    "                same_chars = [\n",
    "                    char1\n",
    "                    for (char1, char2) in zip(row, comparison)\n",
    "                    if char1 == char2\n",
    "                ]\n",
    "                return ''.join(same_chars)\n",
    "\n",
    "find_boxes(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 3: No Matter How You Slice It](https://adventofcode.com/2018/day/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_input(data):\n",
    "    reg = re.compile('#(\\d+) @ (\\d+),(\\d+): (\\d+)x(\\d+)')\n",
    "    datum = namedtuple('datum', 'claim,left,top,width,height')\n",
    "    parsed = []\n",
    "    for line in data:\n",
    "        match = reg.match(line)\n",
    "        \n",
    "        parsed.append(\n",
    "            datum(*[int(i) for i in match.groups()])\n",
    "        )\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def find_overlaps(data):\n",
    "    overlaps = defaultdict(list)\n",
    "    repeated = 0\n",
    "    \n",
    "    for datum in data:\n",
    "        for x in range(datum.width):\n",
    "            for y in range(datum.height):\n",
    "                p = Point(datum.left + x, datum.top + y)\n",
    "                overlaps[p].append(datum.claim)\n",
    "    return overlaps\n",
    "\n",
    "\n",
    "def count_overlaps(data):\n",
    "    overlaps = find_overlaps(data)\n",
    "    return len([\n",
    "        claims for claims in overlaps.values()\n",
    "        if len(claims) > 1\n",
    "    ])\n",
    "    \n",
    "        \n",
    "test_data = [\n",
    "    '#1 @ 1,3: 4x4',\n",
    "    '#2 @ 3,1: 4x4',\n",
    "    '#3 @ 5,5: 2x2',\n",
    "]\n",
    "test_data = parse_input(test_data)\n",
    "assert count_overlaps(test_data) == 4\n",
    "\n",
    "data = parse_input(Input(3).readlines())\n",
    "count_overlaps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_unique(data):\n",
    "    remainin_claims = set(\n",
    "        datum.claim for datum in data\n",
    "    )\n",
    "    overlaps = find_overlaps(data)\n",
    "    \n",
    "    for claims in overlaps.values():\n",
    "        if len(claims) == 1:\n",
    "            continue\n",
    "        remainin_claims -= set(claims)\n",
    "    assert len(list(remainin_claims)) == 1\n",
    "    return list(remainin_claims)[0]\n",
    "\n",
    "\n",
    "assert find_unique(test_data) == 3\n",
    "find_unique(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 4: Repose Record](https://adventofcode.com/2018/day/4)\n",
    "\n",
    "The most fiddly portion of this problem was just parsing the data! The incoming events log are stateful, in that the current line applies to the most recently seen guard id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Event = namedtuple('Event', 'asleep,wake_up')\n",
    "\n",
    "\n",
    "def parse_data(lines):\n",
    "    \"\"\"\n",
    "        Sort random order events before grouping them into\n",
    "        (alseep, wake_up) datetime pairs.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for line in lines:\n",
    "        date_str = line[1:17]\n",
    "        event = line[19:]\n",
    "        data.append(\n",
    "            (\n",
    "                datetime.strptime(date_str, '%Y-%m-%d %H:%M'),\n",
    "                event\n",
    "            )\n",
    "        )\n",
    "    data = sorted(data)\n",
    "    \n",
    "    guard_events = defaultdict(list)\n",
    "\n",
    "    current_guard = None\n",
    "    data_iter = iter(data)\n",
    "    try:\n",
    "        while True:\n",
    "            event = next(data_iter)\n",
    "            guard_number = re.match('Guard #(\\d+)', event[1])\n",
    "            \n",
    "            if guard_number:\n",
    "                current_guard = int(guard_number.groups()[0])\n",
    "                asleep = next(data_iter)\n",
    "            else:\n",
    "                asleep = event\n",
    "\n",
    "            wakes_up = next(data_iter)\n",
    "\n",
    "            guard_events[current_guard].append(\n",
    "                Event(\n",
    "                    asleep[0],\n",
    "                    wakes_up[0]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    except StopIteration:\n",
    "        pass        \n",
    "    return guard_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew, now that that's done we can get on with the problem!\n",
    "\n",
    "All we need to do here is find the guard that's spent the most time asleep, the multiple the time he's most likely to be asleep (i.e the most observed sleepiest minute) and multiple that by the guard's id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101262"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minutes_asleep(guard_events):\n",
    "    sleep_counter = defaultdict(int)\n",
    "    \n",
    "    for guard, events in guard_events.items():\n",
    "        for asleep, wake_up in events:\n",
    "            sleep_counter[guard] += wake_up.minute - asleep.minute\n",
    "            \n",
    "    return sleep_counter\n",
    "\n",
    "\n",
    "def most_common_time_asleep(sleepiest_events):\n",
    "    min_counter = Counter()\n",
    "    for asleep, awake in sleepiest_events:\n",
    "        min_counter.update(\n",
    "            range(asleep.minute, awake.minute)\n",
    "        )\n",
    "    return min_counter.most_common(1)[0][0]\n",
    "\n",
    "    \n",
    "def strat_1(guard_events):\n",
    "    sleep_counter = minutes_asleep(guard_events)\n",
    "\n",
    "    sleepiest_guard = None\n",
    "    max_time_asleep = 0\n",
    "    for guard, time_asleep in sleep_counter.items():\n",
    "        if time_asleep > max_time_asleep:\n",
    "            max_time_asleep = time_asleep\n",
    "            sleepiest_guard = guard\n",
    "    \n",
    "    common_minute = most_common_time_asleep(\n",
    "        guard_events[sleepiest_guard]\n",
    "    )\n",
    "    return sleepiest_guard * common_minute\n",
    "\n",
    "    \n",
    "\n",
    "test_data = [\n",
    "    '[1518-11-01 00:00] Guard #10 begins shift',\n",
    "    '[1518-11-01 00:05] falls asleep',\n",
    "    '[1518-11-01 00:25] wakes up',\n",
    "    '[1518-11-01 00:30] falls asleep',\n",
    "    '[1518-11-01 00:55] wakes up',\n",
    "    '[1518-11-01 23:58] Guard #99 begins shift',\n",
    "    '[1518-11-02 00:40] falls asleep',\n",
    "    '[1518-11-02 00:50] wakes up',\n",
    "    '[1518-11-03 00:05] Guard #10 begins shift',\n",
    "    '[1518-11-03 00:24] falls asleep',\n",
    "    '[1518-11-03 00:29] wakes up',\n",
    "    '[1518-11-04 00:02] Guard #99 begins shift',\n",
    "    '[1518-11-04 00:36] falls asleep',\n",
    "    '[1518-11-04 00:46] wakes up',\n",
    "    '[1518-11-05 00:03] Guard #99 begins shift',\n",
    "    '[1518-11-05 00:45] falls asleep',\n",
    "    '[1518-11-05 00:55] wakes up',\n",
    "]\n",
    "\n",
    "test_data = parse_data(test_data)\n",
    "assert strat_1(test_data) == 240\n",
    "data = parse_data(Input(4).readlines())\n",
    "strat_1(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part two we're required to find the most common time to be asleep across all guards, and multuple that by the guard responsible for being asleep at that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strat_2(guard_events):\n",
    "    guard_counters = defaultdict(Counter)\n",
    "    for guard, events in guard_events.items():\n",
    "        for asleep, awake in events:\n",
    "            guard_counters[guard].update(\n",
    "                range(asleep.minute, awake.minute)\n",
    "            )\n",
    "\n",
    "    most_occurances = 0\n",
    "    most_occurances_minute = 0\n",
    "    most_occurances_guard = 0\n",
    "    for guard, counter in guard_counters.items():\n",
    "        most_common_min, occurances = counter.most_common(1)[0]\n",
    "        if occurances > most_occurances:\n",
    "            most_occurances = occurances\n",
    "            most_occurances_minute = most_common_min\n",
    "            most_occurances_guard = guard\n",
    "            \n",
    "    return most_occurances_guard * most_occurances_minute\n",
    "            \n",
    "    \n",
    "assert strat_2(test_data) == 4455\n",
    "strat_2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 5: Alchemical Reduction](https://adventofcode.com/2018/day/5)\n",
    "\n",
    "This day specifically came with a warning about the size of the input data, so I downloaded it directly. This contained a new line which I did not strip, so got the wrong result for quite a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9462"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce_polymer(data, remove_char=''):\n",
    "    if remove_char:\n",
    "        data = cat(char for char in data if char.lower() != remove_char.lower())\n",
    "        \n",
    "    data = list(data)\n",
    "    index = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            char = data[index]\n",
    "            next_char = data[index + 1]\n",
    "        except IndexError:\n",
    "            break\n",
    "\n",
    "        if char != next_char and char.lower() == next_char.lower():\n",
    "            # Remove current char an the next\n",
    "            del data[index]\n",
    "            del data[index]\n",
    "            if index > 0:\n",
    "                index -= 1\n",
    "        else:\n",
    "            index += 1\n",
    "    return cat(data)\n",
    "\n",
    "\n",
    "test_input = 'dabAcCaCBAcCcaDA'\n",
    "assert reduce_polymer(test_input) == 'dabCBAcaDA'\n",
    "\n",
    "data = Input(5).read()\n",
    "len(reduce_polymer(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4952"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ultimate_reduction(data):\n",
    "    chars = set(data.lower())\n",
    "    shortest = None\n",
    "    for char in chars:\n",
    "        reduced = reduce_polymer(data, char)\n",
    "        if shortest is None or len(reduced) < shortest:\n",
    "            shortest = len(reduced)\n",
    "    return shortest\n",
    "\n",
    "\n",
    "assert ultimate_reduction(test_input) == 4\n",
    "ultimate_reduction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
