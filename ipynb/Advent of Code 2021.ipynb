{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e9fe55",
   "metadata": {},
   "source": [
    "# [Advent of Code 2021](https://adventofcode.com/2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d06a3d",
   "metadata": {},
   "source": [
    "# The toolbox\n",
    "\n",
    "\n",
    "Generalised pieces of code that either can be used in multiple questions or that simply makes understand the implementation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "2f400016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter, namedtuple\n",
    "from itertools import chain, count\n",
    "from heapq import heappush, heappop\n",
    "from typing import Iterator\n",
    "import copy \n",
    "import io\n",
    "import math\n",
    "import operator\n",
    "\n",
    "\n",
    "def Input(day, parser=str.strip, whole_file=False):\n",
    "    \"Fetch the data input from disk.\"\n",
    "    filename = f\"../data/advent2021/input{day}.txt\"\n",
    "    with open(filename) as fin:\n",
    "        if whole_file:\n",
    "            return parser(fin)\n",
    "        return mapt(parser, fin)\n",
    "\n",
    "\n",
    "def mapt(fn, *args):\n",
    "    \"Do a map, and convert the results to a tuple\"\n",
    "    return tuple(map(fn, *args))\n",
    "\n",
    "\n",
    "avg = lambda n: sum(n) / len(n)\n",
    "\n",
    "\n",
    "NEIGHBOUR8_DELTAS = (\n",
    "    (-1, -1), ( 0, -1), (1, -1),\n",
    "    (-1,  0),           (1,  0),\n",
    "    (-1,  1), ( 0,  1), (1,  1),\n",
    ")\n",
    "\n",
    "NEIGHBOUR4_DELTAS = (\n",
    "              ( 0, -1),\n",
    "    (-1,  0),           (1,  0),\n",
    "              ( 0,  1),\n",
    ")\n",
    "\n",
    "\n",
    "def neighbours4(x, y):\n",
    "    return tuple((x + dx, y + dy) for dx, dy in NEIGHBOUR4_DELTAS)\n",
    "\n",
    "\n",
    "def neighbours8(x, y):\n",
    "    return tuple((x + dx, y + dy) for dx, dy in NEIGHBOUR8_DELTAS)\n",
    "\n",
    "\n",
    "def a_star(start, h_func, moves, cost=lambda s1, s2: 1):\n",
    "    \"\"\"A* implementation.\n",
    "\n",
    "    Finds the shortest sequence of states from to a goal (a state where\n",
    "    the hueristic function - h_func - is zero). We use a heap\n",
    "    as our priority queue, and processes those with the smallest\n",
    "    overall cost first (the cost of the path + the distance to target).\n",
    "\n",
    "    start:  the initial state to explore from\n",
    "    h_func: hueristic function that gives a \"distance\" to to target state,\n",
    "            when this is zero we're done.\n",
    "    moves:  function that generates all possible states from the supplied state\n",
    "            (these can go bakckwards, but will never be processed)\n",
    "    cost:   the cost of moving from ones state to another\n",
    "\n",
    "    return: list of states used to find the final state, wll raise an exception\n",
    "            if none was found.\n",
    "\n",
    "    \"\"\"\n",
    "    # The priority queue that we'll be reading from\n",
    "    queue = []\n",
    "    # We often care about the path taken, so persist the lowest costing path\n",
    "    # to each state\n",
    "    previous = {start: None}\n",
    "    # Lookup of state costs, we initialize at zero for the starting state\n",
    "    costs = {start: 0}\n",
    "\n",
    "    # Initialize our queue, this is ordered by path cost (f(n) = g(n) + h(n))\n",
    "    add_to_queue = lambda state: heappush(queue, (costs[state] + h_func(state), state))\n",
    "\n",
    "    # Recursively walk backwards to build the full path\n",
    "    get_path = (\n",
    "        lambda state: [] if state is None else get_path(previous[state]) + [state]\n",
    "    )\n",
    "\n",
    "    # Set the intial position and go!\n",
    "    add_to_queue(start)\n",
    "\n",
    "    while queue:\n",
    "        _, state = heappop(queue)\n",
    "        if h_func(state) == 0:\n",
    "            # We're done!\n",
    "            return get_path(state)\n",
    "\n",
    "        for new_state in moves(state):\n",
    "            new_cost = costs[state] + cost(state, new_state)\n",
    "\n",
    "            if new_state not in costs or new_cost < costs[new_state]:\n",
    "                # We've found a new state or a better path\n",
    "                costs[new_state] = new_cost\n",
    "                previous[new_state] = state\n",
    "                # We've modified our costs in some way, we need\n",
    "                # to explore from this state so add to the heap\n",
    "                add_to_queue(new_state)\n",
    "\n",
    "    # No solution was found\n",
    "    raise Exception(\"No solution for A* was discovered.\")\n",
    "    \n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Generic tree node.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self._children = []\n",
    "        self.parent = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'<Node 0x:{id(self)} name={self.name}>'\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return tuple(self._children)\n",
    "    \n",
    "    @children.setter\n",
    "    def children(self, value):\n",
    "        self._children = []\n",
    "        for val in value:\n",
    "            self.add_child(val)\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self._children.append(child)\n",
    "        child.parent = self\n",
    "    \n",
    "    def remove_child(self, child):\n",
    "        self._children.remove(child)\n",
    "    \n",
    "    @property\n",
    "    def ancestors(self):\n",
    "        node = self\n",
    "        while node.parent:\n",
    "            yield node.parent\n",
    "            node = node.parent\n",
    "    \n",
    "    @property\n",
    "    def depth(self):\n",
    "        return len(list(self.ancestors))\n",
    "    \n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return len(self._children) == 0\n",
    "    \n",
    "    @property\n",
    "    def root(self):\n",
    "        node = self\n",
    "        while node.parent:\n",
    "            node = node.parent\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdda12",
   "metadata": {},
   "source": [
    "## [Day 1](https://adventofcode.com/2021/day/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "f68cbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_increasing_measurements(scans):\n",
    "    return sum(scan > scans[index - 1] for index, scan in enumerate(scans[1:], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "id": "6174b9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1121"
      ]
     },
     "execution_count": 1251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = Input(1, int)\n",
    "count_increasing_measurements(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "id": "bf587fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1121, 'Day 1.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "ed89ab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1065"
      ]
     },
     "execution_count": 1253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = [data1[i:i + 3] for i in range(len(data1) - 2)]\n",
    "count_increasing_measurements(mapt(sum, chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "id": "c169bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1065, 'Day 1.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d2753",
   "metadata": {},
   "source": [
    "## [Day 2](https://adventofcode.com/2021/day/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "id": "4a9e9673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2036120"
      ]
     },
     "execution_count": 1255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def follow_commands(commands):\n",
    "    x = d = 0\n",
    "    for direction, amount in commands:\n",
    "        if direction == \"forward\":\n",
    "            x += amount\n",
    "        elif direction == \"down\":\n",
    "            d += amount\n",
    "        elif direction == \"up\":\n",
    "            d -= amount\n",
    "        else:\n",
    "            print(\"unknown command!\")\n",
    "    return x * d\n",
    "\n",
    "\n",
    "def parse_input_2(line):\n",
    "    chunks = line.split(\" \")\n",
    "    return chunks[0], int(chunks[1])\n",
    "\n",
    "\n",
    "data2 = Input(2, parse_input_2)\n",
    "follow_commands(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "id": "402663c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2036120, \"Day 2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "id": "2dfa6170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015547716"
      ]
     },
     "execution_count": 1257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def follow_commands(commands):\n",
    "    x = d = aim = 0\n",
    "    for direction, amount in commands:\n",
    "        if direction == \"forward\":\n",
    "            x += amount\n",
    "            d += aim * amount\n",
    "        elif direction == \"down\":\n",
    "            aim += amount\n",
    "        elif direction == \"up\":\n",
    "            aim -= amount\n",
    "        else:\n",
    "            print(\"unknown command!\")\n",
    "    return x * d\n",
    "\n",
    "\n",
    "follow_commands(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "id": "1b8c1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2015547716, \"Day 2.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0e0a7",
   "metadata": {},
   "source": [
    "## [Day 3](https://adventofcode.com/2021/day/3)\n",
    "\n",
    "Not the prettiest, but a nice example of using `zip` to unzip the string into individual digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "id": "d7d68b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3969000"
      ]
     },
     "execution_count": 1259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_power_consumption(report: list[list[int]]) -> int:\n",
    "    digits = list(zip(*report))\n",
    "    avg_bits = [round(avg(digits[bit_index])) for bit_index in range(len(digits))]\n",
    "\n",
    "    most_common = lambda index: str(avg_bits[index])\n",
    "    least_common = lambda index: str(int(not avg_bits[index]))\n",
    "\n",
    "    gamma = \"\".join(mapt(most_common, range(len(digits))))\n",
    "    epsilon = \"\".join(mapt(least_common, range(len(digits))))\n",
    "    return int(gamma, 2) * int(epsilon, 2)\n",
    "\n",
    "\n",
    "def parse_input(line):\n",
    "    return mapt(int, line.strip())\n",
    "\n",
    "\n",
    "data3 = Input(3, parse_input)\n",
    "find_power_consumption(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "id": "a1ee480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 3969000, 'Day 3.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb4b4b",
   "metadata": {},
   "source": [
    "Part two was fun, here we continue to abuse bools and recurse through `bit_criteria` to remove digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "id": "361cdfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4267809"
      ]
     },
     "execution_count": 1261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bit_criteria(\n",
    "    report: list[list[int]], keep_most_common: bool, bit_index: int = 0\n",
    ") -> int:\n",
    "    if len(report) == 1:\n",
    "        return report[0]\n",
    "\n",
    "    digits = list(zip(*report))\n",
    "    avg_bit = avg(digits[bit_index])\n",
    "\n",
    "    # I can't be bothered to use Decimal ROUND UP here...\n",
    "    most_common = 1 if avg_bit == 0.5 else round(avg_bit)\n",
    "\n",
    "    winning_bit = most_common if keep_most_common else int(not most_common)\n",
    "\n",
    "    return bit_criteria(\n",
    "        [line for line in report if line[bit_index] == winning_bit],\n",
    "        keep_most_common,\n",
    "        bit_index + 1,\n",
    "    )\n",
    "\n",
    "\n",
    "def find_life_support_rating(report: list[list[int]]) -> int:\n",
    "    oxygen_generator = bit_criteria(report[:], True)\n",
    "    co2_scrubber = bit_criteria(report[:], False)\n",
    "\n",
    "    to_int = lambda bits: int(\"\".join(mapt(str, bits)), 2)\n",
    "\n",
    "    return to_int(oxygen_generator) * to_int(co2_scrubber)\n",
    "\n",
    "\n",
    "find_life_support_rating(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "46896a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 4267809, 'Day 3.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb01e6",
   "metadata": {},
   "source": [
    "## [Day 4](https://adventofcode.com/2021/day/4)\n",
    "\n",
    "Not particularly clean, and I don't really think all the sets are required, I could have simply read out rows and cols from a larger list! Oh well, did the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "647025a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8580"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BingoBoard = namedtuple(\"BingoBoard\", \"rows,cols\")\n",
    "\n",
    "\n",
    "def play_bingo(numbers: [int], boards: [BingoBoard], win_last: bool = False) -> int:\n",
    "    # translate boards to a list of sets so we can easily remove seen numbers\n",
    "    board_nums = dict(\n",
    "        (boardId, [*[set(r) for r in board.rows], *[set(c) for c in board.cols]])\n",
    "        for boardId, board in enumerate(boards)\n",
    "    )\n",
    "\n",
    "    # keep track of the most recent winningi board\n",
    "    winning_board = None\n",
    "\n",
    "    # track boards that are still in play\n",
    "    active_boards = set(board_nums.keys())\n",
    "\n",
    "    seen_numbers = set()\n",
    "    for number in numbers:\n",
    "        seen_numbers.add(number)\n",
    "\n",
    "        for board_id in list(active_boards):\n",
    "            for row_or_col_nums in board_nums[board_id]:\n",
    "                row_or_col_nums -= seen_numbers\n",
    "                if len(row_or_col_nums) == 0:\n",
    "                    # Don't exit now as we'll need to remove this number\n",
    "                    # from the row or col too!\n",
    "                    winning_board = board_id\n",
    "\n",
    "                    if board_id in active_boards:\n",
    "                        active_boards.remove(board_id)\n",
    "\n",
    "        have_a_winner = not win_last and winning_board is not None\n",
    "        should_last_win = win_last and len(active_boards) == 0\n",
    "        if have_a_winner or should_last_win:\n",
    "            break\n",
    "\n",
    "    if winning_board:\n",
    "        remaining = set()\n",
    "        for nums in board_nums[winning_board]:\n",
    "            remaining |= nums\n",
    "        return sum(remaining) * number\n",
    "\n",
    "    print(\"No winning board found!\")\n",
    "    return -1\n",
    "\n",
    "\n",
    "def parse_input(lines: [str]) -> [[int], [BingoBoard]]:\n",
    "    numbers = []\n",
    "    boards = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not numbers:\n",
    "            numbers = mapt(int, line.strip().split(\",\"))\n",
    "            continue\n",
    "\n",
    "        if not line.strip():\n",
    "            # add a new board\n",
    "            boards.append(BingoBoard([], []))\n",
    "            continue\n",
    "        boards[-1].rows.append(mapt(int, line.strip().split()))\n",
    "\n",
    "    # rotate rows into cols\n",
    "    for board in boards:\n",
    "        board.cols.extend((list(zip(*board.rows))))\n",
    "\n",
    "    return (numbers, boards)\n",
    "\n",
    "\n",
    "data4 = Input(4, parse_input, whole_file=True)\n",
    "play_bingo(*data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "e22a3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 8580, \"Day 4.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "c3f4f8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9576"
      ]
     },
     "execution_count": 1265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_bingo(*data4, win_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "f1e11d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 9576, \"Day 4.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9201e",
   "metadata": {},
   "source": [
    "## [Day 5](https://adventofcode.com/2021/day/5)\n",
    "\n",
    "Slight trick on this one was to sort the inputs so we knew we'd always be _increasing_ in x or y, makes finding the delta much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "edbf9ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6710"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point = namedtuple(\"Point\", \"x,y\")\n",
    "\n",
    "\n",
    "def count_overlapping_points(point_lines, horizontal_only=True):\n",
    "    area = Counter()\n",
    "\n",
    "    if horizontal_only:\n",
    "        point_lines = [\n",
    "            line\n",
    "            for line in point_lines\n",
    "            if line[0].x == line[1].x or line[0].y == line[1].y\n",
    "        ]\n",
    "\n",
    "    for start, stop in point_lines:\n",
    "        if start.x == stop.x:\n",
    "            delta = Point(0, 1)\n",
    "        elif start.y == stop.y:\n",
    "            delta = Point(1, 0)\n",
    "        elif start.y < stop.y:\n",
    "            delta = Point(1, 1)\n",
    "        else:\n",
    "            delta = Point(1, -1)\n",
    "\n",
    "        line = [start]\n",
    "        while line[-1] != stop:\n",
    "            last_point = line[-1]\n",
    "            next_point = Point(last_point.x + delta.x, last_point.y + delta.y)\n",
    "            line.append(next_point)\n",
    "\n",
    "        area.update(line)\n",
    "\n",
    "    return len([val for _, val in area.items() if val >= 2])\n",
    "\n",
    "\n",
    "def parse_input(line):\n",
    "    chunks = line.split(\" -> \")\n",
    "    points = (\n",
    "        Point(*mapt(int, chunks[0].split(\",\"))),\n",
    "        Point(*mapt(int, chunks[1].split(\",\"))),\n",
    "    )\n",
    "\n",
    "    # sorting the points ensures we start from the left most one first\n",
    "    return sorted(points)\n",
    "\n",
    "\n",
    "data5 = Input(5, parse_input)\n",
    "count_overlapping_points(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "9497e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 6710, 'Day 5.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "id": "99ab74aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20121"
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_overlapping_points(data5, horizontal_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "id": "cfd0222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 20121, 'Day 5.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f8c2c",
   "metadata": {},
   "source": [
    "## Day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "id": "0ba1a27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346063"
      ]
     },
     "execution_count": 1271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grow_lantern_fish(fish: [int], remaining_days: int):\n",
    "    # first naive recursive implementation\n",
    "    if remaining_days == 0:\n",
    "        return fish\n",
    "    \n",
    "    next_generation = []\n",
    "    for f in fish:\n",
    "        next_val = f - 1\n",
    "        # -1 here as the zeroth day counts\n",
    "        if next_val == -1:\n",
    "            next_generation.append(8)\n",
    "            next_val = 6\n",
    "        next_generation.append(next_val)\n",
    "    return grow_lantern_fish(next_generation, remaining_days - 1)\n",
    "        \n",
    "            \n",
    "\n",
    "data5_input = \"1,5,5,1,5,1,5,3,1,3,2,4,3,4,1,1,3,5,4,4,2,1,2,1,2,1,2,1,5,2,1,5,1,2,2,1,5,5,5,1,1,1,5,1,3,4,5,1,2,2,5,5,3,4,5,4,4,1,4,5,3,4,4,5,2,4,2,2,1,3,4,3,2,3,4,1,4,4,4,5,1,3,4,2,5,4,5,3,1,4,1,1,1,2,4,2,1,5,1,4,5,3,3,4,1,1,4,3,4,1,1,1,5,4,3,5,2,4,1,1,2,3,2,4,4,3,3,5,3,1,4,5,5,4,3,3,5,1,5,3,5,2,5,1,5,5,2,3,3,1,1,2,2,4,3,1,5,1,1,3,1,4,1,2,3,5,5,1,2,3,4,3,4,1,1,5,5,3,3,4,5,1,1,4,1,4,1,3,5,5,1,4,3,1,3,5,5,5,5,5,2,2,1,2,4,1,5,3,3,5,4,5,4,1,5,1,5,1,2,5,4,5,5,3,2,2,2,5,4,4,3,3,1,4,1,2,3,1,5,4,5,3,4,1,1,2,2,1,2,5,1,1,1,5,4,5,2,1,4,4,1,1,3,3,1,3,2,1,5,2,3,4,5,3,5,4,3,1,3,5,5,5,5,2,1,1,4,2,5,1,5,1,3,4,3,5,5,1,4,3\"\n",
    "data5 = mapt(int, data5_input.split(','))\n",
    "len(grow_lantern_fish(data5, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "id": "10e0de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 346063, 'Day 6.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "683504ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572358335990"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_fish_in_state(fish: [int], days: int) -> int:\n",
    "    # find the fish in each state, creating a list of length 8\n",
    "    days_state = [fish.count(days_left) for days_left in range(9)]\n",
    "\n",
    "    for _ in range(days):\n",
    "        reproducing_fish = days_state[0]\n",
    "        # remove the fish that have reproduced\n",
    "        days_state = days_state[1:]\n",
    "        # reset day 8 with new fish\n",
    "        days_state.append(reproducing_fish)\n",
    "        # move that have reproduced to day 6\n",
    "        days_state[6] += reproducing_fish\n",
    "    return sum(days_state)\n",
    "\n",
    "count_fish_in_state(data5, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "id": "33935393",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1572358335990, 'Day 6.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d0271",
   "metadata": {},
   "source": [
    "## [Day 7](https://adventofcode.com/2021/day/7)\n",
    "\n",
    "Here, we're looking to minimise [aggregating discrepancies](https://www.johnmyleswhite.com/notebook/2013/03/22/modes-medians-and-means-an-unifying-perspective/).\n",
    "\n",
    "For part one, we're looking at **absolute deviation**, or that the value of the discrepancy increases linearly with the distance from it. We're seeking to minimise this value, which equates to the median value of the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "id": "8a57f2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341534"
      ]
     },
     "execution_count": 1275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def align_crab_subs(positions):\n",
    "    positions = sorted(positions)\n",
    "    median = positions[int(len(positions) / 2)]\n",
    "    return sum(abs(pos - median) for pos in positions)\n",
    "\n",
    "\n",
    "data7 = Input(7, lambda l: mapt(int, l.split(\",\")))[0]\n",
    "align_crab_subs(data7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "id": "ee71ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 341534, 'Day 7.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434d7d0",
   "metadata": {},
   "source": [
    "Then for part two, we're told that it's the sum of integers up to a limit, the more general form of which is `sum(1..n) -> n(n+1)/2` ([wikipedia](https://en.wikipedia.org/wiki/1_%2B_2_%2B_3_%2B_4_%2B_%E2%8B%AF)). If we expand we have `n^2 + n / 2` , because `n^2 >> n` we can make an approximation that we're looking to minimise the the average square distance, which is another way of expressing the mean.\n",
    "\n",
    "This tells us the we can expect the answer to be around the mean value - I got lucky, as it was just the integer of the mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "id": "07183f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93397632"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def align_crab_subs2(positions):\n",
    "    mean = int(avg(positions))\n",
    "    return sum(int(abs(pos - mean) * (abs(pos - mean) + 1) / 2) for pos in positions)\n",
    "\n",
    "align_crab_subs2(data7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "0ea9f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 93397632, 'Day 7.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd60d7bc",
   "metadata": {},
   "source": [
    "## [Day 8](https://adventofcode.com/2021/day/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "ad3092cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 1279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_easy_digits(mappings: [[str], [str]]) -> int:\n",
    "    outputs = [out for _, out in mappings]\n",
    "    return sum(len(digits) in (2, 3, 4, 7) for digits in chain(*outputs))\n",
    "\n",
    "\n",
    "def parse_input(line):\n",
    "    inputs, outputs = line.strip().split(\" | \")\n",
    "    return inputs.split(\" \"), outputs.split(\" \")\n",
    "\n",
    "\n",
    "data8 = Input(8, parse_input)\n",
    "count_easy_digits(data8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "id": "2b23947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 362, \"Day 8.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dbabc5",
   "metadata": {},
   "source": [
    "For the second part I spent a bunch of time staring at the digits and figuring out the logical combinations for them. I did toy with creating a general solution for this but it didn't seem worth it given the number of characters!\n",
    "\n",
    "```\n",
    "  0:      1:      2:      3:      4:\n",
    " aaaa    ....    aaaa    aaaa    ....\n",
    "b    c  .    c  .    c  .    c  b    c\n",
    "b    c  .    c  .    c  .    c  b    c\n",
    " ....    ....    dddd    dddd    dddd\n",
    "e    f  .    f  e    .  .    f  .    f\n",
    "e    f  .    f  e    .  .    f  .    f\n",
    " gggg    ....    gggg    gggg    ....\n",
    "\n",
    "  5:      6:      7:      8:      9:\n",
    " aaaa    aaaa    aaaa    aaaa    aaaa\n",
    "b    .  b    .  .    c  b    c  b    c\n",
    "b    .  b    .  .    c  b    c  b    c\n",
    " dddd    dddd    ....    dddd    dddd\n",
    ".    f  e    f  .    f  e    f  .    f\n",
    ".    f  e    f  .    f  e    f  .    f\n",
    " gggg    gggg    ....    gggg    gggg\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "id": "20b983a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020159"
      ]
     },
     "execution_count": 1281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def created_digit_to_code_map(codes):\n",
    "    mapping = {}\n",
    "    lengths = defaultdict(list)\n",
    "\n",
    "    for code in codes:\n",
    "        lengths[len(code)].append(frozenset(code))\n",
    "\n",
    "    # Map unqiue lengths\n",
    "    mapping[1] = lengths[2][0]\n",
    "    mapping[4] = lengths[4][0]\n",
    "    mapping[7] = lengths[3][0]\n",
    "    mapping[8] = lengths[7][0]\n",
    "\n",
    "    # 0, 6, 9\n",
    "    for code in lengths[6]:\n",
    "        # 6 does not contain 1\n",
    "        if not mapping[1].issubset(code):\n",
    "            mapping[6] = code\n",
    "        # 9 containes 4\n",
    "        elif mapping[4].issubset(code):\n",
    "            mapping[9] = code\n",
    "        # must be 0\n",
    "        else:\n",
    "            mapping[0] = code\n",
    "\n",
    "    # 2, 3, 5\n",
    "    for code in lengths[5]:\n",
    "        # 3 contains 1\n",
    "        if mapping[1].issubset(code):\n",
    "            mapping[3] = code\n",
    "        # 5 is a subset of 9\n",
    "        elif code.issubset(mapping[9]):\n",
    "            mapping[5] = code\n",
    "        # must be 2\n",
    "        else:\n",
    "            mapping[2] = code\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def build_mapping(mappings: [[str], [str]]):\n",
    "    total = 0\n",
    "    for inputs, outputs in mappings:\n",
    "        mapping = created_digit_to_code_map(inputs)\n",
    "\n",
    "        code_to_num = dict((chars, val) for val, chars in mapping.items())\n",
    "        digits = [code_to_num[frozenset(out)] for out in outputs]\n",
    "        num = 0\n",
    "        for out in outputs:\n",
    "            num *= 10\n",
    "            num += code_to_num[frozenset(out)]\n",
    "        total += num\n",
    "    return total\n",
    "\n",
    "\n",
    "build_mapping(data8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "id": "869a3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1020159, 'Day 8.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff5892",
   "metadata": {},
   "source": [
    "## [Day 9](https://adventofcode.com/2021/day/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "id": "ca2589b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603"
      ]
     },
     "execution_count": 1283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_low_points(grid: [[int]]) -> [(int, int)]:\n",
    "    low_points = []\n",
    "\n",
    "    for y, row in enumerate(grid):\n",
    "        for x, cell in enumerate(row):\n",
    "            for (nx, ny) in neighbours4(x, y):\n",
    "                if nx < 0 or ny < 0 or nx >= len(row) or ny >= len(grid):\n",
    "                    continue\n",
    "                if grid[ny][nx] <= cell:\n",
    "                    break\n",
    "            else:\n",
    "                low_points.append((x, y))\n",
    "    return low_points\n",
    "\n",
    "\n",
    "def calclualate_risk(grid: [[int]]) -> int:\n",
    "    low_points = find_low_points(grid)\n",
    "    return sum(grid[y][x] + 1 for (x, y) in low_points)\n",
    "\n",
    "\n",
    "def parse_data(line):\n",
    "    return mapt(int, line.strip())\n",
    "\n",
    "\n",
    "data9 = Input(9, parse_data)\n",
    "calclualate_risk(data9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "f89f259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 603, 'Day 9.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "id": "4f72f7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786780"
      ]
     },
     "execution_count": 1285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_basins(grid: [[int]]) -> [[(int, int)]]:\n",
    "    roots = find_low_points(grid)\n",
    "\n",
    "    basins = []\n",
    "\n",
    "    xmax = len(grid[0])\n",
    "    ymax = len(grid)\n",
    "\n",
    "    for root in roots:\n",
    "        basin = [root]\n",
    "        to_explore = [root]\n",
    "\n",
    "        while to_explore:\n",
    "            x, y = to_explore.pop()\n",
    "\n",
    "            for (nx, ny) in neighbours4(x, y):\n",
    "                if nx < 0 or ny < 0 or nx >= xmax or ny >= ymax:\n",
    "                    # out of bounds\n",
    "                    continue\n",
    "\n",
    "                if grid[ny][nx] == 9:\n",
    "                    # hit a high point, and cannot continue\n",
    "                    continue\n",
    "\n",
    "                if (nx, ny) in basin:\n",
    "                    # seen before, can ignore this time\n",
    "                    continue\n",
    "                to_explore.append((nx, ny))\n",
    "                basin.append((nx, ny))\n",
    "\n",
    "        basins.append(basin)\n",
    "    return basins\n",
    "\n",
    "\n",
    "def avoid_largest_basins(grid: [[int]]) -> int:\n",
    "    basins = find_basins(grid)\n",
    "    basins = sorted(basins, key=lambda b: len(b), reverse=True)\n",
    "    return len(basins[0]) * len(basins[1]) * len(basins[2])\n",
    "\n",
    "\n",
    "avoid_largest_basins(data9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e511a",
   "metadata": {},
   "source": [
    "## [Day 10](https://adventofcode.com/2021/day/10)\n",
    "\n",
    "Using a stack here makes life a lot simpler, it's a classic parsing technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "e334fe4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464991"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_valid_line(line: str) -> (bool, str):\n",
    "    \"\"\"\n",
    "    Checks if line is valid, if it is return True and any missing\n",
    "    characters, otherwise False and the first offending character.\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "\n",
    "    brackets = {\"[\": \"]\", \"(\": \")\", \"<\": \">\", \"{\": \"}\"}\n",
    "    close_brackets = dict((val, key) for key, val in brackets.items())\n",
    "\n",
    "    for char in line:\n",
    "        if char in brackets:\n",
    "            # new opening bracket\n",
    "            stack.append(char)\n",
    "            continue\n",
    "        if stack[-1] != close_brackets[char]:\n",
    "            # got a different close bracket, this is an error\n",
    "            return False, char\n",
    "        stack.pop()\n",
    "    return True, \"\".join(brackets[k] for k in stack[::-1])\n",
    "\n",
    "\n",
    "def find_syntax_error_score(lines):\n",
    "    scores = {\n",
    "        \")\": 3,\n",
    "        \"]\": 57,\n",
    "        \"}\": 1197,\n",
    "        \">\": 25137,\n",
    "    }\n",
    "    total_score = 0\n",
    "    for line in lines:\n",
    "        is_valid, error_char = is_valid_line(line)\n",
    "        if not is_valid:\n",
    "            total_score += scores[error_char]\n",
    "    return total_score\n",
    "\n",
    "\n",
    "data10 = Input(10)\n",
    "find_syntax_error_score(data10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "32c69fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 464991, 'Day 10.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "29d245e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662008566"
      ]
     },
     "execution_count": 1288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_autocomplete_score(chars):\n",
    "    scores = {\n",
    "        \")\": 1,\n",
    "        \"]\": 2,\n",
    "        \"}\": 3,\n",
    "        \">\": 4,\n",
    "    }\n",
    "    score = 0\n",
    "\n",
    "    for char in chars:\n",
    "        score *= 5\n",
    "        score += scores[char]\n",
    "    return score\n",
    "\n",
    "\n",
    "def find_autocomplete_score(lines):\n",
    "    scores = []\n",
    "\n",
    "    for line in lines:\n",
    "        is_valid, missing_chars = is_valid_line(line)\n",
    "        if is_valid:\n",
    "            scores.append(calculate_autocomplete_score(missing_chars))\n",
    "\n",
    "    sorted_scores = sorted(scores)\n",
    "    mid_index = int(len(sorted_scores) / 2)\n",
    "    return sorted_scores[mid_index]\n",
    "\n",
    "\n",
    "find_autocomplete_score(data10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "927eaac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 3662008566, 'Day 10.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54355beb",
   "metadata": {},
   "source": [
    "## [Day 11](https://adventofcode.com/2021/day/11)\n",
    "\n",
    "Today's was quite fun! The only real difficulty was reading the question.. using `>= 9` held me up for much longer than it should have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "454103ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1743"
      ]
     },
     "execution_count": 1290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def advance_octopus_grid(octopus_grid: [[int]]) -> ([[int]], int):\n",
    "    \"\"\"\n",
    "    Advances all octopuses state.\n",
    "\n",
    "    Returns a new grid of octopusses and the number that flashed during\n",
    "    this step.\n",
    "    \"\"\"\n",
    "    octopus_grid = [l.copy() for l in octopus_grid]\n",
    "    # first advance all values\n",
    "    remaining_flashes = set()\n",
    "    for x in range(10):\n",
    "        for y in range(10):\n",
    "            octopus_grid[y][x] += 1\n",
    "\n",
    "            if octopus_grid[y][x] > 9:\n",
    "                remaining_flashes.add((x, y))\n",
    "\n",
    "    did_flash = set()\n",
    "    while remaining_flashes:\n",
    "        x, y = remaining_flashes.pop()\n",
    "\n",
    "        if (x, y) in did_flash:\n",
    "            # this octopus has flashed, ignore\n",
    "            continue\n",
    "\n",
    "        for nx, ny in neighbours8(x, y):\n",
    "            if nx < 0 or nx > 9 or ny < 0 or ny > 9:\n",
    "                # out of bounds, ignore\n",
    "                continue\n",
    "\n",
    "            octopus_grid[ny][nx] += 1\n",
    "\n",
    "            if octopus_grid[ny][nx] > 9:\n",
    "                remaining_flashes.add((nx, ny))\n",
    "\n",
    "        did_flash.add((x, y))\n",
    "\n",
    "    # For all that flashed, set their energy to 0\n",
    "    for x, y in list(did_flash):\n",
    "        octopus_grid[y][x] = 0\n",
    "\n",
    "    return octopus_grid, len(did_flash)\n",
    "\n",
    "\n",
    "def count_flashes(octopus_grid: [[int]], n: int) -> int:\n",
    "    total_flashes = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        octopus_grid, flashes = advance_octopus_grid(octopus_grid)\n",
    "        total_flashes += flashes\n",
    "    return total_flashes\n",
    "\n",
    "\n",
    "data11 = \"\"\"1443668646\n",
    "7686735716\n",
    "4261576231\n",
    "3361258654\n",
    "4852532611\n",
    "5587113732\n",
    "1224426757\n",
    "5155565133\n",
    "6488377862\n",
    "8267833811\"\"\".split(\n",
    "    \"\\n\"\n",
    ")\n",
    "\n",
    "data11 = [list(mapt(int, l)) for l in data11]\n",
    "\n",
    "count_flashes(data11, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "048ffb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "id": "d730ff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 1292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_first_simultaneous_flash(octopus_grid: [[int]]) -> int:\n",
    "    for step in count(1):\n",
    "        octopus_grid, flashes = advance_octopus_grid(octopus_grid)\n",
    "        if flashes == 100:\n",
    "            break\n",
    "    return step\n",
    "\n",
    "\n",
    "find_first_simultaneous_flash(data11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "id": "150ffe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 364"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fbe9ce",
   "metadata": {},
   "source": [
    "## [Day 12](https://adventofcode.com/2021/day/12)\n",
    "\n",
    "First graph question! Below uses an adjacency list to keep track of connected nodes, and performs a depth-first-search on the tree, recursively exploring a single path until it terminates and tracking branches as we go. There is undoubtedly an efficient technique for reusing explored paths, which I may come and rewrite at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "id": "551f44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths(tree, multi_visit=False, node=\"start\", current_path=None):\n",
    "    if current_path is None:\n",
    "        current_path = [\"start\"]\n",
    "\n",
    "    if node == \"end\":\n",
    "        yield current_path\n",
    "\n",
    "    for child_node in tree[node]:\n",
    "        path = current_path[:]\n",
    "\n",
    "        if child_node.islower() and child_node in path:\n",
    "            if not multi_visit:\n",
    "                # cannot revisit a small cave\n",
    "                continue\n",
    "            if current_path[0] == \"+\":\n",
    "                # already visited a small cave in this path, cannot revisit\n",
    "                continue\n",
    "            if child_node in (\"start\", \"end\"):\n",
    "                # do not allow visiting end roots more than once\n",
    "                continue\n",
    "            # mark this path to say we've visited a small cave already\n",
    "            path.insert(0, \"+\")\n",
    "\n",
    "        path.append(child_node)\n",
    "\n",
    "        yield from find_all_paths(tree, multi_visit, child_node, path)\n",
    "\n",
    "\n",
    "def count_paths(tree, multi_visit=False):\n",
    "    path_count = 0\n",
    "    for path in find_all_paths(tree, multi_visit):\n",
    "        path_count += 1\n",
    "    return path_count\n",
    "\n",
    "\n",
    "def parse_input(lines):\n",
    "    nodes = defaultdict(list)\n",
    "\n",
    "    for line in lines:\n",
    "        left, right = line.strip().split(\"-\")\n",
    "        # connections are bi-directional\n",
    "        nodes[left].append(right)\n",
    "        nodes[right].append(left)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "id": "ab75469d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3887"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data12 = Input(12, parse_input, whole_file=True)\n",
    "count_paths(data12, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "b5683e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 3887, 'Day 12.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "id": "37280e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 4.87 ms, total: 1.82 s\n",
      "Wall time: 1.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104834"
      ]
     },
     "execution_count": 1297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "count_paths(data12, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "id": "76747eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 104834, 'Day 12.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554c01f",
   "metadata": {},
   "source": [
    "## [Day 13: Transparent Origami](https://adventofcode.com/2021/day/13)\n",
    "\n",
    "Today's problem wasn't too tricky, the only thing to recognise here was how to perform the folding of the grid. The question tells us that we're always folding UP or LEFT, so we only need to move points that are higher in x or y respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "id": "eb58fd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 1299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perform_fold(grid, axis, fold_point):\n",
    "    # which points are being flipped, x or y?\n",
    "    index = 1 if axis == \"y\" else 0\n",
    "\n",
    "    new_grid = set()\n",
    "    for x, y in grid:\n",
    "        new_point = [x, y]\n",
    "\n",
    "        # we only care about points on the other side of the fold\n",
    "        if new_point[index] > fold_point:\n",
    "            # as we're folding LEFT or UP, this is negative\n",
    "            distance_to_fold = new_point[index] - fold_point\n",
    "            new_point[index] -= 2 * distance_to_fold\n",
    "        new_grid.add(tuple(new_point))\n",
    "    return list(new_grid)\n",
    "\n",
    "\n",
    "def fold_grid(grid, folds):\n",
    "    for fold in folds:\n",
    "        axis, fold_point = fold\n",
    "        grid = perform_fold(grid, axis, fold_point)\n",
    "    return grid\n",
    "\n",
    "\n",
    "def print_grid(grid):\n",
    "    max_x = max(x for x, _ in grid)\n",
    "    max_y = max(y for _, y in grid)\n",
    "\n",
    "    for y in range(max_y + 1):\n",
    "        row = []\n",
    "        for x in range(max_x + 1):\n",
    "            char = \"#\" if (x, y) in grid else \".\"\n",
    "            row.append(char)\n",
    "        print(\"\".join(row))\n",
    "\n",
    "\n",
    "def count_points_after_folds(grid, folds, display_output=False):\n",
    "    grid = fold_grid(grid, folds)\n",
    "    if display_output:\n",
    "        print_grid(grid)\n",
    "    return len(grid)\n",
    "\n",
    "\n",
    "def parse_input(lines):\n",
    "    grid = []\n",
    "    folds = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if \"fold\" in line:\n",
    "            left_chunk, value = line.split('=')\n",
    "            axis = left_chunk[-1]\n",
    "            folds.append((axis, int(value)))\n",
    "        else:\n",
    "            x, y = line.split(\",\")\n",
    "            point = (int(x), int(y))\n",
    "            grid.append(point)\n",
    "    return grid, folds\n",
    "\n",
    "\n",
    "data13 = Input(13, parse_input, whole_file=True)\n",
    "count_points_after_folds(data13[0], data13[1][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "id": "ac5494d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 602, \"Day 13.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "id": "fbba16a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".##...##..####...##.#..#.####..##..#..#\n",
      "#..#.#..#.#.......#.#..#....#.#..#.#.#.\n",
      "#....#..#.###.....#.####...#..#....##..\n",
      "#....####.#.......#.#..#..#...#....#.#.\n",
      "#..#.#..#.#....#..#.#..#.#....#..#.#.#.\n",
      ".##..#..#.#.....##..#..#.####..##..#..#\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 1301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_points_after_folds(data13[0], data13[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "id": "9e9e6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 92, \"Day 13.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde262be",
   "metadata": {},
   "source": [
    "## [Day 14](https://adventofcode.com/2021/day/14)\n",
    "\n",
    "Another problem that cannot be brute forced, as the memory complexity gets out of hand quite quickly. I started with a simple recursive solution, not knowing that the state of the overall polymer wouldn't be required for the second part... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "id": "d84d738a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 1314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grow_poylmer(polymer: str, rules: dict[str, str]) -> str:\n",
    "    pairs = [a + b for a, b in zip(polymer, polymer[1:])]\n",
    "    new_polymer = [polymer[0]]\n",
    "\n",
    "    for pair in pairs:\n",
    "        if pair in rules:\n",
    "            new_polymer.append(rules[pair])\n",
    "        new_polymer.append(pair[1])\n",
    "    return \"\".join(new_polymer)\n",
    "\n",
    "\n",
    "def polymerization(polymer: str, rules: dict[str, str]) -> int:\n",
    "    for _ in range(10):\n",
    "        polymer = grow_poylmer(polymer, rules)\n",
    "    chars = Counter(polymer)\n",
    "    counts = chars.most_common()\n",
    "    return counts[0][1] - counts[-1][1]\n",
    "\n",
    "\n",
    "def parse_input(lines: [str]) -> (str, dict[str, str]):\n",
    "    polymer, _, *lines = lines\n",
    "    rules = {}\n",
    "    for line in lines:\n",
    "        pair, char = line.strip().split(\" -> \")\n",
    "        rules[pair] = char\n",
    "    return polymer, rules\n",
    "\n",
    "\n",
    "data14 = Input(14, parse_input, whole_file=True)\n",
    "\n",
    "L = \"\"\"NNCB\n",
    "\n",
    "CH -> B\n",
    "HH -> N\n",
    "CB -> H\n",
    "NH -> C\n",
    "HB -> C\n",
    "HC -> B\n",
    "HN -> C\n",
    "NN -> C\n",
    "BH -> H\n",
    "NC -> B\n",
    "NB -> B\n",
    "BN -> B\n",
    "BB -> N\n",
    "BC -> B\n",
    "CC -> N\n",
    "CN -> C\"\"\".split('\\n')\n",
    "\n",
    "data14 = parse_input(L)\n",
    "\n",
    "polymerization(*data14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "id": "2744c00d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Day 14.1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fn/qx2038nd1gz2scb7_h9flqt40000gq/T/ipykernel_9344/4058552353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2891\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Day 14.1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Day 14.1"
     ]
    }
   ],
   "source": [
    "assert _ == 2891, 'Day 14.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8e593",
   "metadata": {},
   "source": [
    "Similar to the lantern fish from day 6, the brute force solution simply will not work for the second part. Again the key observation is that the order of what is growing is not required for the result, so we only need to track the pair and character frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "id": "3b23c060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174673055076"
      ]
     },
     "execution_count": 1312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def polymerization_count(polymer: str, rules: dict[str, str], n: int=40) -> int:\n",
    "    # rather than keep track of the entire polymer, instead track the growth\n",
    "    pair_counts = defaultdict(int)\n",
    "    char_counts = defaultdict(int)\n",
    "\n",
    "    # initalise our tracking dicts\n",
    "    for a, b in zip(polymer, polymer[1:]):\n",
    "        pair_counts[a + b] += 1\n",
    "\n",
    "    for char in polymer:\n",
    "        char_counts[char] += 1\n",
    "\n",
    "    for _ in range(n):\n",
    "        current_occurances = list(pair_counts.items())\n",
    "        for pair, occurance in current_occurances:\n",
    "            if pair in rules:\n",
    "                new_char = rules[pair]\n",
    "                # all current pairs are broken...\n",
    "                pair_counts[pair] -= occurance\n",
    "                # ...and new ones created\n",
    "                pair_counts[pair[0] + new_char] += occurance\n",
    "                pair_counts[new_char + pair[1]] += occurance\n",
    "\n",
    "                char_counts[new_char] += occurance\n",
    "\n",
    "    return max(char_counts.values()) - min(char_counts.values())\n",
    "\n",
    "\n",
    "\n",
    "polymerization_count(*data14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 4607749009683, 'Day 14.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09271416",
   "metadata": {},
   "source": [
    "## [Day 15: Chiton](https://adventofcode.com/2021/day/15)\n",
    "\n",
    "Our first offical BFS! As we know the distance to the target state (although not the cost), we our hueristic is simply the manhatten distance from the current location to the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cheapest_path(grid):\n",
    "    start = (0, 0)\n",
    "\n",
    "    max_y = len(grid) - 1\n",
    "    max_x = len(grid[0]) - 1\n",
    "\n",
    "    def h_func(state):\n",
    "        x, y = state\n",
    "        return max_y - y + max_x - x\n",
    "\n",
    "    def moves(state):\n",
    "        x, y = state\n",
    "        for nx, ny in neighbours4(x, y):\n",
    "            if nx < 0 or ny < 0 or nx > max_x or ny > max_y:\n",
    "                continue\n",
    "            yield (nx, ny)\n",
    "\n",
    "    def cost(old_state, new_state):\n",
    "        ox, oy = old_state\n",
    "        x, y = new_state\n",
    "        return grid[oy][ox] + grid[y][x]\n",
    "\n",
    "    cheapest_path = a_star(start, h_func, moves, cost)\n",
    "    total_cost = sum(grid[y][x] for (x, y) in cheapest_path)\n",
    "    return total_cost - grid[0][0]\n",
    "\n",
    "\n",
    "data15 = Input(15, lambda l: mapt(int, l.strip()))\n",
    "find_cheapest_path(data15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 393, \"Day 15.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cheapest_path_large(tile):\n",
    "    # we need to build a larger grid...\n",
    "    x_lim = len(tile[0])\n",
    "    y_lim = len(tile)\n",
    "\n",
    "    grid = []\n",
    "\n",
    "    for _ in range(y_lim * 5):\n",
    "        grid.append([None] * x_lim * 5)\n",
    "\n",
    "    for y_step, y_start in enumerate(range(0, y_lim * 5, y_lim)):\n",
    "        for x_step, x_start in enumerate(range(0, x_lim * 5, x_lim)):\n",
    "            for dy in range(y_lim):\n",
    "                for dx in range(x_lim):\n",
    "                    x = x_start + dx\n",
    "                    y = y_start + dy\n",
    "\n",
    "                    original_value = tile[dy][dx]\n",
    "                    new_value = original_value + x_step + y_step\n",
    "                    if new_value > 9:\n",
    "                        new_value = new_value % 10 + 1\n",
    "                    grid[y][x] = new_value\n",
    "    # now the grid has been built, find the solution!\n",
    "    return find_cheapest_path(grid)\n",
    "\n",
    "\n",
    "find_cheapest_path_large(data15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a15a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2823, 'Day 15.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c1827",
   "metadata": {},
   "source": [
    "## Day 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad954cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Packet = namedtuple(\"Packet\", \"version,type_id,children,val\")\n",
    "\n",
    "\n",
    "def hex_to_binary(hex_str):\n",
    "    to_hex = lambda c: format(int(c, 16), \"b\").rjust(4, \"0\")\n",
    "    return \"\".join(map(to_hex, hex_str))\n",
    "\n",
    "\n",
    "def unpack_literal_value(packet_stream):\n",
    "    unpacked_binary = \"\"\n",
    "    while True:\n",
    "        chunk = packet_stream.read(5)\n",
    "        more_bit, body = chunk[0], chunk[1:]\n",
    "        unpacked_binary += body\n",
    "        if int(more_bit) == 0:\n",
    "            break\n",
    "    return int(unpacked_binary, 2)\n",
    "\n",
    "\n",
    "def read_packet(packet_stream):\n",
    "    version_str = packet_stream.read(3)\n",
    "\n",
    "    if version_str == \"\":\n",
    "        # reached the end of the stream\n",
    "        return\n",
    "\n",
    "    version = int(version_str, 2)\n",
    "    type_id = int(packet_stream.read(3), 2)\n",
    "    sub_packets = []\n",
    "    val = None\n",
    "\n",
    "    if type_id == 4:\n",
    "        # the packet is a literal value\n",
    "        val = unpack_literal_value(packet_stream)\n",
    "    else:\n",
    "        # this is some kind of operator\n",
    "        length_type_id = int(packet_stream.read(1), 2)\n",
    "        if length_type_id == 0:\n",
    "            # the next 15 bits are sub packets, create a new stream and consume\n",
    "            sub_packet_length = int(packet_stream.read(15), 2)\n",
    "            val = sub_packet_length\n",
    "\n",
    "            substream = io.StringIO(packet_stream.read(val))\n",
    "            while True:\n",
    "                packet = read_packet(substream)\n",
    "                if not packet:\n",
    "                    break\n",
    "                sub_packets.append(packet)\n",
    "        else:\n",
    "            # the next N packets are subpackets\n",
    "            val = int(packet_stream.read(11), 2)\n",
    "            for _ in range(val):\n",
    "                packet = read_packet(packet_stream)\n",
    "                sub_packets.append(packet)\n",
    "\n",
    "    return Packet(version, type_id, sub_packets, val)\n",
    "\n",
    "\n",
    "def find_transmission_version_total(transmission):\n",
    "    binary = hex_to_binary(transmission)\n",
    "    stream = io.StringIO(binary)\n",
    "\n",
    "    def sum_versions(packet):\n",
    "        total = packet.version\n",
    "        total += sum(map(sum_versions, packet.children))\n",
    "        return total\n",
    "\n",
    "    packet = read_packet(stream)\n",
    "    return sum_versions(packet)\n",
    "\n",
    "\n",
    "data15 = \"220D6448300428021F9EFE668D3F5FD6025165C00C602FC980B45002A40400B402548808A310028400C001B5CC00B10029C0096011C0003C55003C0028270025400C1002E4F19099F7600142C801098CD0761290021B19627C1D3007E33C4A8A640143CE85CB9D49144C134927100823275CC28D9C01234BD21F8144A6F90D1B2804F39B972B13D9D60939384FE29BA3B8803535E8DF04F33BC4AFCAFC9E4EE32600C4E2F4896CE079802D4012148DF5ACB9C8DF5ACB9CD821007874014B4ECE1A8FEF9D1BCC72A293A0E801C7C9CA36A5A9D6396F8FCC52D18E91E77DD9EB16649AA9EC9DA4F4600ACE7F90DFA30BA160066A200FC448EB05C401B8291F22A2002051D247856600949C3C73A009C8F0CA7FBCCF77F88B0000B905A3C1802B3F7990E8029375AC7DDE2DCA20C2C1004E4BE9F392D0E90073D31634C0090667FF8D9E667FF8D9F0C01693F8FE8024000844688FF0900010D8EB0923A9802903F80357100663DC2987C0008744F8B5138803739EB67223C00E4CC74BA46B0AD42C001DE8392C0B0DE4E8F660095006AA200EC198671A00010E87F08E184FCD7840289C1995749197295AC265B2BFC76811381880193C8EE36C324F95CA69C26D92364B66779D63EA071008C360098002191A637C7310062224108C3263A600A49334C19100A1A000864728BF0980010E8571EE188803D19A294477008A595A53BC841526BE313D6F88CE7E16A7AC60401A9E80273728D2CC53728D2CCD2AA2600A466A007CE680E5E79EFEB07360041A6B20D0F4C021982C966D9810993B9E9F3B1C7970C00B9577300526F52FCAB3DF87EC01296AFBC1F3BC9A6200109309240156CC41B38015796EABCB7540804B7C00B926BD6AC36B1338C4717E7D7A76378C85D8043F947C966593FD2BBBCB27710E57FDF6A686E00EC229B4C9247300528029393EC3BAA32C9F61DD51925AD9AB2B001F72B2EE464C0139580D680232FA129668\"\n",
    "find_transmission_version_total(data15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c90e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1012, 'Day 15.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_transmssion(transmission):\n",
    "    binary = hex_to_binary(transmission)\n",
    "    stream = io.StringIO(binary)    \n",
    "    root_packet = read_packet(stream)\n",
    "    \n",
    "    def unpack_packet(packet):\n",
    "        unpacked_children = [unpack_packet(child) for child in packet.children]\n",
    "        type_operations = {\n",
    "            0: lambda: sum(unpacked_children),\n",
    "            1: lambda: reduce(op.mul, unpacked_children),\n",
    "            2: lambda: min(unpacked_children),\n",
    "            3: lambda: max(unpacked_children),\n",
    "            4: lambda: packet.val,\n",
    "            5: lambda: int(op.gt(*unpacked_children)),\n",
    "            6: lambda: int(op.lt(*unpacked_children)),\n",
    "            7: lambda: int(op.eq(*unpacked_children))\n",
    "        }\n",
    "        return type_operations[packet.type_id]()    \n",
    "    return unpack_packet(root_packet)\n",
    "            \n",
    "    \n",
    "\n",
    "perform_transmssion(data15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2223947372407, 'Day 16.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2d8c0",
   "metadata": {},
   "source": [
    "## [Day 17: Trick Shot](https://adventofcode.com/2021/day/17)\n",
    "\n",
    "This is a really nasty solution that just brute-forces the solution by testing a wide range of possible values. Absolutely zero elegance here at all and probably my least favourite solution to AoC ever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exhaust_until_miss(dx, dy, target):\n",
    "    x = y = max_y = 0\n",
    "    for _ in range(1000):\n",
    "        x += dx\n",
    "        y += dy\n",
    "\n",
    "        max_y = max(max_y, y)\n",
    "\n",
    "        if (\n",
    "            target[0][0] <= x\n",
    "            and x <= target[0][1]\n",
    "            and target[1][0] <= y\n",
    "            and y <= target[1][1]\n",
    "        ):\n",
    "            return max_y\n",
    "        elif x > target[0][1] or y < target[1][0]:\n",
    "            # have overshot, can break early\n",
    "            break\n",
    "\n",
    "        dy -= 1\n",
    "        dx -= dx > 0 - dx < 0\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "def trickshot(target: [[int, int], [int, int]]) -> int:\n",
    "    winner = -1\n",
    "    total = 0\n",
    "\n",
    "    # we know the target is max -248 in y, so any more and we immediately overshoot\n",
    "    for dy in range(-250, 1000):\n",
    "        has_hit = False\n",
    "        # we know that the target is to the right, so there's no point looking at negative values of dx\n",
    "        for dx in range(1000):\n",
    "            max_y = exhaust_until_miss(dx, dy, target)\n",
    "            lands_in_target = max_y >= 0\n",
    "            winner = max(winner, max_y)\n",
    "            total += lands_in_target\n",
    "\n",
    "            if not has_hit and lands_in_target:\n",
    "                has_hit = True\n",
    "            elif has_hit and not lands_in_target:\n",
    "                # we will never land in the target for further values of dx\n",
    "                break\n",
    "\n",
    "    return winner, total\n",
    "\n",
    "\n",
    "data17 = ((29, 73), (-248, -194))\n",
    "\n",
    "answers = trickshot(data17)\n",
    "print(f\"Part 1: {answers[0]}\")\n",
    "print(f\"Part 2: {answers[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0717482",
   "metadata": {},
   "source": [
    "## [Day 18: Snailfish](https://adventofcode.com/2021/day/18)\n",
    "\n",
    "\n",
    "What a problem! This was really fun once I spotted the continual pre-order traversal, but it took me quite a while to actually conceptualise that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnailFishNode(Node):\n",
    "    def __add__(self, other: SnailFishNode) -> SnailFishNode:\n",
    "        \"\"\"\n",
    "        Support a simple node1 + node2 operation.\n",
    "        \"\"\"\n",
    "        root = SnailFishNode(name=None)\n",
    "\n",
    "        root.add_child(self.copy())\n",
    "        root.add_child(other.copy())\n",
    "\n",
    "        # keep reducing the tree until no changes occur\n",
    "        while root._reduce():\n",
    "            pass\n",
    "        return root\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Utility for viewing the tree as Advent of Code displays it.\"\"\"\n",
    "        if self.is_leaf:\n",
    "            return str(self.name)\n",
    "        return \"[\" + \",\".join(str(child) for child in self.children) + \"]\"\n",
    "\n",
    "    def copy(self) -> SnailFishNode:\n",
    "        \"\"\"Create a fresh copy of this SnailFishNode.\"\"\"\n",
    "        new_node = SnailFishNode(self.name)\n",
    "\n",
    "        for child in self.children:\n",
    "            new_node.add_child(child.copy())\n",
    "\n",
    "        return new_node\n",
    "\n",
    "    def _reduce(self) -> bool:\n",
    "        \"\"\"\n",
    "        Perform a single reduction and return if was succesful or not.\n",
    "        \"\"\"\n",
    "        for node in visit_pre_order(self):\n",
    "            if node.depth == 4 and not node.is_leaf:\n",
    "                node._explode()\n",
    "                return True\n",
    "\n",
    "        for node in visit_pre_order(self):\n",
    "            if node.is_leaf and node.name >= 10:\n",
    "                node._split()\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _explode(self) -> None:\n",
    "        nodes = visit_pre_order(self.root)\n",
    "\n",
    "        previous_leaf_node = None\n",
    "        next_leaf_node = None\n",
    "\n",
    "        for node in nodes:\n",
    "            if node == self:\n",
    "                # find the next leaf that are NOT under this node\n",
    "                # advance past the two children\n",
    "                next(nodes)\n",
    "                next(nodes)\n",
    "\n",
    "                for node in nodes:\n",
    "                    if node.is_leaf:\n",
    "                        next_leaf_node = node\n",
    "                        break\n",
    "                break\n",
    "\n",
    "            if node.is_leaf:\n",
    "                previous_leaf_node = node\n",
    "\n",
    "        # add current children to nearest neighbours...\n",
    "        if previous_leaf_node:\n",
    "            previous_leaf_node.name += self.children[0].name\n",
    "        if next_leaf_node:\n",
    "            next_leaf_node.name += self.children[1].name\n",
    "        # ...and update current node\n",
    "        self.name = 0\n",
    "        self.children = []\n",
    "\n",
    "    def _split(self) -> None:\n",
    "        value = self.name\n",
    "        left = SnailFishNode(math.floor(value / 2))\n",
    "        right = SnailFishNode(math.ceil(value / 2))\n",
    "\n",
    "        self.children = [left, right]\n",
    "        self.name = None\n",
    "\n",
    "    @property\n",
    "    def magnitude(self) -> int:\n",
    "        total = 0\n",
    "\n",
    "        if self.is_leaf:\n",
    "            return self.name\n",
    "\n",
    "        total += 3 * self.children[0].magnitude\n",
    "        total += 2 * self.children[1].magnitude\n",
    "\n",
    "        return total\n",
    "\n",
    "\n",
    "def visit_pre_order(node: Node) -> Iterator[Node]:\n",
    "    \"\"\"Visit a Tree in pre-order.\n",
    "    \n",
    "      A\n",
    "     / \\\n",
    "    B   C\n",
    "    \n",
    "    A -> B -> C\n",
    "    \"\"\"\n",
    "    yield node\n",
    "    for child in node.children:\n",
    "        yield from visit_pre_order(child)\n",
    "\n",
    "\n",
    "def snailfish_to_tree(snailfish_number, parent=None):\n",
    "    if parent is None:\n",
    "        parent = SnailFishNode(None)\n",
    "\n",
    "    for child in snailfish_number:\n",
    "        if isinstance(child, list):\n",
    "            child_node = SnailFishNode(None)\n",
    "            snailfish_to_tree(child, child_node)\n",
    "        else:\n",
    "            child_node = SnailFishNode(child)\n",
    "        parent.add_child(child_node)\n",
    "\n",
    "    return parent\n",
    "\n",
    "\n",
    "# hmmm using eval to parse test input. Lovely.\n",
    "parse_input = lambda l: snailfish_to_tree(eval(l))\n",
    "data18 = Input(18, parse_input)\n",
    "\n",
    "\n",
    "def reduce_trees(trees, verbose=True) -> SnailFishNode:\n",
    "    reduced_tree = trees[0]\n",
    "    for tree in trees[1:]:\n",
    "        if verbose:\n",
    "            print(f\"  {t}\")\n",
    "            print(f\"+ {tree}\")\n",
    "\n",
    "        reduced_tree += tree\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"= {reduced_tree}\\n\")\n",
    "    return reduced_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f51abc",
   "metadata": {},
   "source": [
    "Lets check that the reduction is being applied correctly.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88562ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"\"\"[[[0,[4,5]],[0,0]],[[[4,5],[2,6]],[9,5]]]\n",
    "[7,[[[3,7],[4,3]],[[6,3],[8,8]]]]\n",
    "[[2,[[0,8],[3,4]]],[[[6,7],1],[7,[1,6]]]]\n",
    "[[[[2,4],7],[6,[0,5]]],[[[6,8],[2,8]],[[2,1],[4,5]]]]\n",
    "[7,[5,[[3,8],[1,4]]]]\n",
    "[[2,[2,2]],[8,[8,1]]]\n",
    "[2,9]\n",
    "[1,[[[9,3],9],[[9,0],[0,7]]]]\n",
    "[[[5,[7,4]],7],1]\n",
    "[[[[4,2],2],6],[8,7]]\"\"\".split('\\n')\n",
    "\n",
    "reduce_trees(mapt(parse_input, test_input), True).magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affef7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_trees(data18, False).magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 3793, 'Day 18.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2defcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def find_largest_sum(trees):\n",
    "    winner =  0\n",
    "    \n",
    "    for idx, left in enumerate(trees[:-2]):\n",
    "        for right in trees[idx + 1:]:\n",
    "            winner = max(winner, (left + right).magnitude)\n",
    "            winner = max(winner, (right + left).magnitude)\n",
    "    return winner\n",
    "\n",
    "find_largest_sum(data18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c367e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 4695, 'Day 18.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75fad5",
   "metadata": {},
   "source": [
    "## [Day 19: Beacon Scanner](https://adventofcode.com/2021/day/19)\n",
    "\n",
    "Well this one was pretty horrific. Rather than cycle through each permutation I did something like this:\n",
    "\n",
    "1. Each scanner has a series of beacons it’s scanned. For each beacon find the manhatten distance to each other beacon. This gives us an orientation agnostic layout.\n",
    "2. Compare these distances between different scanners, those that share >= 12 distances overlap.\n",
    "3. Of those that overlap, compare the  points that share a distance. Treat one as fixed, and inspect the other, identify the correct order of the points against the first and the signs those points need.\n",
    "4. Update all points in the second with the new order and signs\n",
    "5. The absolute location of this scanner can be found by comparing it to the first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "class Scanner:\n",
    "    def __init__(self, location):\n",
    "        self._points = []\n",
    "        self.location = location\n",
    "\n",
    "    @property\n",
    "    def points(self):\n",
    "        return tuple(self._points)\n",
    "\n",
    "    @points.setter\n",
    "    def points(self, points):\n",
    "        self._points = points\n",
    "\n",
    "    def add_point(self, scan: [int, int, int]):\n",
    "        self._points.append(scan)\n",
    "\n",
    "    @property\n",
    "    def distances(self):\n",
    "        \"\"\"Manhatten distances from one point to every other point.\"\"\"\n",
    "        for idx, point in enumerate(self.points):\n",
    "            distances = []\n",
    "            for other_point in self.points:\n",
    "                dist = manhatten_distance(point, other_point)\n",
    "                distances.append(dist)\n",
    "            yield idx, distances\n",
    "\n",
    "    def find_overlaps(self, other_scanner):\n",
    "        for scan1_point_idx, distances in self.distances:\n",
    "            for scan2_point_idx, other_distances in other_scanner.distances:\n",
    "                overlaps = set(distances) & set(other_distances)\n",
    "                if len(overlaps) >= 12:\n",
    "                    yield scan1_point_idx, scan2_point_idx, overlaps\n",
    "\n",
    "\n",
    "def find_scanner_locations(scanners):\n",
    "    scanners[0].location = (0, 0, 0)\n",
    "\n",
    "    # loop through each known scanner, looking for overlaps until\n",
    "    # we've found them all\n",
    "    while [s for s in scanners if s.location is None]:\n",
    "        for scanner_idx, scanner in enumerate(scanners):\n",
    "            if scanner.location is None:\n",
    "                # don't know where this one is, so can't use it to find another..\n",
    "                continue\n",
    "\n",
    "            for other_scanner_idx, other_scanner in enumerate(scanners):\n",
    "                if other_scanner.location:\n",
    "                    # already know this one's location, can ignore\n",
    "                    continue\n",
    "\n",
    "                overlaps = list(scanner.find_overlaps(other_scanner))\n",
    "                if overlaps:\n",
    "                    # these scanners intersect, we can reorient one to the other\n",
    "                    relative_location = reorient_scanner(\n",
    "                        scanner, other_scanner, overlaps\n",
    "                    )\n",
    "                    other_scanner.location = add_points(\n",
    "                        scanner.location, relative_location\n",
    "                    )\n",
    "\n",
    "\n",
    "def reorient_scanner(scanner, other_scanner, overlaps):\n",
    "    # we have to beacons and a set of distances that the overlap\n",
    "    # to with in their own scanners. if we convert the distances back\n",
    "    # to the beacons they represent, we can find the ordering\n",
    "    for scan1_point_idx, scan2_point_idx, overlap in overlaps:\n",
    "        diffs1 = []\n",
    "        diffs2 = []\n",
    "\n",
    "        # find the points that share this distance\n",
    "        beacon_1 = scanner.points[scan1_point_idx]\n",
    "        beacon_2 = other_scanner.points[scan2_point_idx]\n",
    "\n",
    "        for distance in overlap:\n",
    "            if distance == 0:\n",
    "                continue\n",
    "\n",
    "            for p in scanner.points:\n",
    "                if manhatten_distance(beacon_1, p) == distance:\n",
    "                    diffs1.append(sub_points(beacon_1, p))\n",
    "                    break\n",
    "            for p in other_scanner.points:\n",
    "                if manhatten_distance(beacon_2, p) == distance:\n",
    "                    diffs2.append(sub_points(beacon_2, p))\n",
    "                    break\n",
    "\n",
    "        # we have two coordinates that should share the same absolute values in different\n",
    "        # orders and signs\n",
    "        for diff1, diff2 in zip(diffs1, diffs2):\n",
    "            ordering = []\n",
    "            signs = []\n",
    "\n",
    "            for p in diff1:\n",
    "                try:\n",
    "                    position = [abs(d) for d in diff2].index(abs(p))\n",
    "                except ValueError:\n",
    "                    # not sure why this happens.. it shouldn't :|\n",
    "                    continue\n",
    "                ordering.append(position)\n",
    "                signs.append(p // diff2[position])\n",
    "\n",
    "            # make sure that we've seen three unique values\n",
    "            if len(set(ordering)) < 3:\n",
    "                continue\n",
    "\n",
    "            break\n",
    "        break\n",
    "\n",
    "    # we should have the ordering and signs of the second points in relation to the first\n",
    "    # so let's find the relative location of the second scanner and update it's points\n",
    "    new_points = []\n",
    "    for p in other_scanner.points:\n",
    "        new_points.append(tuple(p[idx] * sign for idx, sign in zip(ordering, signs)))\n",
    "    other_scanner.points = new_points\n",
    "\n",
    "    relative_location = sub_points(\n",
    "        scanner.points[scan1_point_idx], other_scanner.points[scan2_point_idx]\n",
    "    )\n",
    "    return relative_location\n",
    "\n",
    "\n",
    "def manhatten_distance(p1, p2):\n",
    "    return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1]) + abs(p1[2] - p2[2])\n",
    "\n",
    "\n",
    "def sub_points(p1, p2):\n",
    "    return tuple(q1 - q2 for q1, q2 in zip(p1, p2))\n",
    "\n",
    "\n",
    "def add_points(p1, p2):\n",
    "    return tuple(q1 + q2 for q1, q2 in zip(p1, p2))\n",
    "\n",
    "\n",
    "def parse_input(lines):\n",
    "    scanners = []\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        if \"scanner\" in line:\n",
    "            scanners.append(Scanner(None))\n",
    "            continue\n",
    "        point = tuple(int(c) for c in line.split(\",\"))\n",
    "        scanners[-1].add_point(point)\n",
    "    return scanners\n",
    "\n",
    "\n",
    "data19 = Input(19, parse_input, True)\n",
    "\n",
    "\n",
    "def find_beacons(scanners):\n",
    "    find_scanner_locations(scanners)\n",
    "    beacons = set()\n",
    "    for scanner in scanners:\n",
    "        for point in scanner.points:\n",
    "            beacons.add(add_points(point, scanner.location))\n",
    "    beacons = sorted(list(beacons))\n",
    "    return beacons\n",
    "\n",
    "\n",
    "def count_beacons(scanners):\n",
    "    beacons = find_beacons(scanners)\n",
    "    return len(beacons)\n",
    "\n",
    "\n",
    "count_beacons(data19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87204f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 457, 'Day 19.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c75eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_distance(scanners):\n",
    "    locations = [s.location for s in scanners]\n",
    "    largest = 0\n",
    "    for i, s1 in enumerate(scanners):\n",
    "        for s2 in scanners[i + 1 :]:\n",
    "            largest = max(largest, manhatten_distance(s1.location, s2.location))\n",
    "    return largest\n",
    "\n",
    "\n",
    "find_largest_distance(data19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d935f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 13243, 'Day 19.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686f2a6",
   "metadata": {},
   "source": [
    "## [Day 20: Trench Map](https://adventofcode.com/2021/day/20)\n",
    "\n",
    "This one was mean.\n",
    "\n",
    "The insight here is the key itself. For our input, the zeroth bit is ON, and the 511th bit OFF. This means that every value in our infinite grid that doesn't touch our active area will translate to ON. So, the first time the area expands, every point will along the boundary be ON. Now, the next time we expand, every bit that that contributes to a value will be ON, or the 511th bit in our key. Thus, it will translate to OFF.\n",
    "\n",
    "This just means that every time we expand, the border is ON, then the next time, it is OFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f536ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(on_pixels):\n",
    "    x_min, x_max, y_min, y_max = limits(on_pixels)\n",
    "    for y in range(y_min - 1, y_max + 2):\n",
    "        for x in range(x_min - 1, x_max + 2):\n",
    "            c = \"#\" if (x, y) in on_pixels else \".\"\n",
    "            print(c, end=\"\")\n",
    "        print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def limits(pixels):\n",
    "    return (\n",
    "        min(p[0] for p in pixels),\n",
    "        max(p[0] for p in pixels),\n",
    "        min(p[1] for p in pixels),\n",
    "        max(p[1] for p in pixels),\n",
    "    )\n",
    "\n",
    "\n",
    "def enhance_image(on_pixels, key, iteration):\n",
    "    new_on_pixels = set()\n",
    "\n",
    "    x_min, x_max, y_min, y_max = limits(on_pixels)\n",
    "\n",
    "    modifable_area = {\n",
    "        (x, y) for x in range(x_min - 1, x_max + 2) for y in range(y_min - 1, y_max + 2)\n",
    "    }\n",
    "    active_area = {\n",
    "        (x, y) for x in range(x_min, x_max + 1) for y in range(y_min, y_max + 1)\n",
    "    }\n",
    "\n",
    "    boundary_bit = key[0] if iteration % 2 == 1 else \".\"\n",
    "\n",
    "    for x, y in modifable_area:\n",
    "        offset = read_image_int(on_pixels, x, y, active_area, boundary_bit)\n",
    "        new_pixel = key[offset]\n",
    "        if new_pixel == \"#\":\n",
    "            new_on_pixels.add((x, y))\n",
    "    return new_on_pixels\n",
    "\n",
    "\n",
    "def get_neighbours(x, y):\n",
    "    neighbours = list(neighbours8(x, y))\n",
    "    neighbours.insert(4, (x, y))\n",
    "    return neighbours\n",
    "\n",
    "\n",
    "def read_image_int(on_pixels, x, y, active_area, boundary_bit):\n",
    "    chars = \"\"\n",
    "    for p in get_neighbours(x, y):\n",
    "        if boundary_bit == \"#\":\n",
    "            c = \"1\" if p in on_pixels or p not in active_area else \"0\"\n",
    "        else:\n",
    "            c = \"1\" if p in on_pixels else \"0\"\n",
    "        chars += c\n",
    "\n",
    "    return int(chars, 2)\n",
    "\n",
    "\n",
    "def parse_input(lines):\n",
    "    key, _, *pixels = lines\n",
    "    on_pixels = set()\n",
    "    for y, line in enumerate(pixels):\n",
    "        for x, char in enumerate(line):\n",
    "            if char == \"#\":\n",
    "                on_pixels.add((x, y))\n",
    "    return on_pixels, key\n",
    "\n",
    "\n",
    "data20 = Input(20, parse_input, True)\n",
    "pixels, key = data20\n",
    "\n",
    "\n",
    "def enhance_n_times(pixels, key, n):\n",
    "    for i in range(n):\n",
    "        pixels = enhance_image(pixels, key, i)\n",
    "    return len(pixels)\n",
    "\n",
    "\n",
    "enhance_n_times(pixels, key, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d652ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 5583, 'Day 20.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhance_n_times(pixels, key, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 19592, 'Day 20.2'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
