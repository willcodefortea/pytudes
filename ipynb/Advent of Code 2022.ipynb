{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e25c7b-e8fd-4db3-aadf-5330412f6056",
   "metadata": {},
   "source": [
    "# [Advent of Code 2022](https://adventofcode.com/2022)\n",
    "<div align=\"right\"><i>Ben Emery<br>December 2022</i></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95016d62-abdf-4a62-9d2a-6a112387df02",
   "metadata": {},
   "source": [
    "## The toolbox\n",
    "\n",
    "Generalised pieces of code that either can be used in multiple questions or that simply makes understand the implementation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a50b0928-2214-4276-87ae-09155de4c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "\n",
    "def Input(day, parser=str.strip, whole_file=False):\n",
    "    \"Fetch the data input from disk.\"\n",
    "    filename = f\"../data/advent2022/input{day}.txt\"\n",
    "    with open(filename) as fin:\n",
    "        if whole_file:\n",
    "            return parser(fin)\n",
    "        return mapt(parser, fin)\n",
    "\n",
    "\n",
    "def mapt(fn, *args):\n",
    "    \"Do a map, and convert the results to a tuple\"\n",
    "    return tuple(map(fn, *args))\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name, data=None):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self._children = []\n",
    "        self.parent = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Node name={self.name} parent={self.parent.name if self.parent else None} data={self.data}>\"\n",
    "\n",
    "    def add_child(self, node):\n",
    "        self._children.append(node)\n",
    "        node.parent = self\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return self._children[:]\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        if self.parent:\n",
    "            return self.parent.root\n",
    "        return self\n",
    "\n",
    "\n",
    "def visit_post_order(node: Node):\n",
    "    for child in node.children:\n",
    "        yield from visit_post_order(child)\n",
    "    yield node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7ae6a-70a4-49cc-bf49-6cbdcbb148d5",
   "metadata": {},
   "source": [
    "## [Day 1](https://adventofcode.com/2022/day/1)\n",
    "\n",
    "Nothing too difficult for day 1, other than remembering how jupyter notebooks / python works...\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c8eda8fa-37d2-4f95-8d5c-9864d5f34035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70296"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(1, lambda s: int(s) if s.strip() else None)\n",
    "\n",
    "def total_calories(data):\n",
    "    elves = [0]\n",
    "    for food in data:\n",
    "        if food is None:\n",
    "            elves.append(0)\n",
    "            continue\n",
    "        elves[-1] += food\n",
    "    return elves\n",
    "\n",
    "elves = total_calories(data)\n",
    "\n",
    "max(elves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "9649e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 70296, \"Day 1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508cf0b-16c2-419a-a8f9-d62d833dcc85",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "941ff200-913f-4963-8e94-971863e98de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205381"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elves.sort()\n",
    "sum(elves[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "b830603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 205381, \"Day 1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c010a0",
   "metadata": {},
   "source": [
    "## [Day 2](https://adventofcode.com/2022/day/2)\n",
    "\n",
    "Again we're being eased in quite gently, unless you get dicts the wrong way around of course..\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "534bc0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11449"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(2, lambda s: s.strip().split(\" \"))\n",
    "\n",
    "ROCK = \"R\"\n",
    "PAPER = \"P\"\n",
    "SCISSORS = \"S\"\n",
    "\n",
    "SCORES = {ROCK: 1, PAPER: 2, SCISSORS: 3}\n",
    "WINNING = {SCISSORS: ROCK, ROCK: PAPER, PAPER: SCISSORS}\n",
    "LOSING = dict((v, k) for k, v in WINNING.items())\n",
    "\n",
    "\n",
    "def map_hands(player_1, player_2):\n",
    "    map_1 = {\"A\": ROCK, \"B\": PAPER, \"C\": SCISSORS}\n",
    "    map_2 = {\"X\": ROCK, \"Y\": PAPER, \"Z\": SCISSORS}\n",
    "    return map_1[player_1], map_2[player_2]\n",
    "\n",
    "\n",
    "def score_game(p1, p2):\n",
    "    score = 3 if p1 == p2 else 0\n",
    "    if p2 == WINNING[p1]:\n",
    "        score = 6\n",
    "    return score + SCORES[p2]\n",
    "\n",
    "\n",
    "def score_all_games(data, hand_mapper):\n",
    "    hands = (map_hands(*d) for d in data)\n",
    "    return sum(score_game(*h) for h in hands)\n",
    "\n",
    "\n",
    "score_all_games(data, map_hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d46691de",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 11449, \"Day 2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5a557",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "6ac08e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13187"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_hands(player_1, player_2):\n",
    "    map_1 = {\"A\": \"R\", \"B\": \"P\", \"C\": \"S\"}\n",
    "    p1 = map_1[player_1]\n",
    "\n",
    "    if player_2 == \"X\":\n",
    "        p2 = LOSING[p1]\n",
    "    elif player_2 == \"Y\":\n",
    "        p2 = p1\n",
    "    elif player_2 == \"Z\":\n",
    "        p2 = WINNING[p1]\n",
    "\n",
    "    return p1, p2\n",
    "\n",
    "\n",
    "score_all_games(data, map_hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "8085d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 13187, \"Day 2.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c233f",
   "metadata": {},
   "source": [
    "## [Day 3](https://adventofcode.com/2022/day/3)\n",
    "\n",
    "First time we need a set, membership tests are O(1) so they make sense to use here. Python makes it quite easy to extend behaviour for part 2, but I find I'm missing a more functional approach..\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "e9a8ad04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7967"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(3)\n",
    "\n",
    "\n",
    "def split_halves(contents):\n",
    "    mid = int(len(contents) / 2)\n",
    "    return contents[:mid], contents[mid:]\n",
    "\n",
    "\n",
    "def find_common(*chunks):\n",
    "    common = set(chunks[0])\n",
    "    for chunk in chunks[1:]:\n",
    "        common &= set(chunk)\n",
    "    return tuple(common)\n",
    "\n",
    "\n",
    "def score(s):\n",
    "    ordinal = ord(s)\n",
    "    if ordinal > 96:\n",
    "        score = ordinal - ord(\"a\") + 1\n",
    "    else:\n",
    "        score = ordinal - ord(\"A\") + 26 + 1\n",
    "    return score\n",
    "\n",
    "\n",
    "def solve(all_data, grouper):\n",
    "    total = 0\n",
    "    for chunks in grouper(all_data):\n",
    "        common = find_common(*chunks)\n",
    "        total += score(common[0])\n",
    "    return total\n",
    "\n",
    "\n",
    "solve(data, lambda lines: map(split_halves, lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "d0d811fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 7967, \"Day 3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "feccd593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2716"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_threes(lines):\n",
    "    for idx in range(0, len(lines) - 1, 3):\n",
    "        yield lines[idx : idx + 3]\n",
    "\n",
    "\n",
    "solve(data, lambda lines: group_threes(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "1ae31104",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2716, \"Day 3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf6a17",
   "metadata": {},
   "source": [
    "## [Day 4](https://adventofcode.com/2022/day/4)\n",
    "\n",
    "\n",
    "I quite enjoyed this one, refactoring the check for detecting supersets meant that I could solve the second part with little effort, which is useually the besy way to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "1c39d9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_line(line):\n",
    "    m = re.match(\"(\\d+)-(\\d+),(\\d+)-(\\d+)\", line)\n",
    "    a, b, c, d = m.groups()\n",
    "    return ((int(a), int(b)), (int(c), int(d)))\n",
    "\n",
    "\n",
    "data = Input(4, parse_line)\n",
    "\n",
    "\n",
    "def count_supersets(lines, is_within):\n",
    "    return sum(is_within(p1, p2) or is_within(p2, p1) for p1, p2 in lines)\n",
    "\n",
    "\n",
    "def contains_entirely(p1, p2):\n",
    "    return p1[0] >= p2[0] and p1[1] <= p2[1]\n",
    "\n",
    "\n",
    "count_supersets(data, contains_entirely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "0f042c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 453, \"Day 4.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed6340",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "687e1e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contains_partially(p1, p2):\n",
    "    return (p1[0] >= p2[0] and p1[0] <= p2[1]) or (p1[1] <= p2[1] and p1[1] >= p2[0])\n",
    "\n",
    "\n",
    "count_supersets(data, contains_partially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "d12351ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 919, \"Day 4.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8409d",
   "metadata": {},
   "source": [
    "## [Day 5](https://adventofcode.com/2022/day/5)\n",
    "\n",
    "Today's felt like one of those puzzles where the hardest part was parsing the input! Reminding myself how python's regex matches works was fun though, and it's also a good lesson about something I've struggled with in the past: pragmatism. Parsing the data doesn't need to be dynamic, we can apply what we know from the inputs to help us out (that there are 9 stacks for example). In fancier language I'd say that we can use a heuristic to simplify things, but who needs that first thing in the morning?\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "e0a8e8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LBLVVTVLP'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data(lines):\n",
    "    stacks = [[], [], [], [], [], [], [], [], []]\n",
    "    instructions = []\n",
    "\n",
    "    def add_to_stack(line):\n",
    "        for match in re.finditer(\"[A-Z]\", line):\n",
    "            stack = match.start() // 4\n",
    "            stacks[stack].insert(0, match.group())\n",
    "\n",
    "    def add_instruction(line):\n",
    "        move, pos_from, pos_to = mapt(int, re.findall(\"\\d+\", line))\n",
    "        instructions.append((move, pos_from - 1, pos_to - 1))\n",
    "\n",
    "    stacks_complete = False\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            stacks_complete = True\n",
    "            continue\n",
    "\n",
    "        if not stacks_complete:\n",
    "            add_to_stack(line)\n",
    "        else:\n",
    "            add_instruction(line)\n",
    "\n",
    "    return stacks, instructions\n",
    "\n",
    "\n",
    "data = Input(5, parse_data, whole_file=True)\n",
    "\n",
    "\n",
    "def single_mover(stacks, instruction):\n",
    "    move, pos_from, pos_to = instruction\n",
    "    for _ in range(move):\n",
    "        val = stacks[pos_from].pop()\n",
    "        stacks[pos_to].append(val)\n",
    "\n",
    "\n",
    "def follow_instructions(stacks, instructions, mover):\n",
    "    new_stacks = [s[:] for s in stacks]\n",
    "\n",
    "    for instruction in instructions:\n",
    "        mover(new_stacks, instruction)\n",
    "    return new_stacks\n",
    "\n",
    "\n",
    "def top_crates(stacks):\n",
    "    return \"\".join(s[-1] for s in stacks)\n",
    "\n",
    "\n",
    "stacks = follow_instructions(*data, single_mover)\n",
    "top_crates(stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "2267eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == \"LBLVVTVLP\", \"Day 5.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff6bde",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "5edf5303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TPFFBDRJD'"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bulk_mover(stacks, instruction):\n",
    "    move, pos_from, pos_to = instruction\n",
    "    stacks[pos_to].extend(stacks[pos_from][-move:])\n",
    "    stacks[pos_from] = stacks[pos_from][:-move]\n",
    "\n",
    "\n",
    "stacks = follow_instructions(*data, bulk_mover)\n",
    "top_crates(stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "7261b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == \"TPFFBDRJD\", \"Day 5.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da6f5cf",
   "metadata": {},
   "source": [
    "## [Day 6](https://adventofcode.com/2022/day/6)\n",
    "\n",
    "Still nothing supuer difficult about this problem, using sets to track uniqueness may be a bit much, but given the size of the data it still returns instantly so why not!\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "d51ad9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(6)[0]\n",
    "\n",
    "\n",
    "def iter_chunks(data, n):\n",
    "    for i in range(0, len(data) - n):\n",
    "        yield i, data[i : i + n]\n",
    "\n",
    "\n",
    "def count_chars_to_packet(data, length=4):\n",
    "    for idx, chunk in iter_chunks(data, length):\n",
    "        if len(set(chunk)) == length:\n",
    "            break\n",
    "    chars_processed = idx + length\n",
    "    return chars_processed\n",
    "\n",
    "\n",
    "count_chars_to_packet(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "ca22d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1598, \"Day 6.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b7e4d",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "f445cc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2414"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_chars_to_packet(data, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "de1c45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2414, \"Day 6.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a773a",
   "metadata": {},
   "source": [
    "## [Day 7](https://adventofcode.com/2022/day/7)\n",
    "\n",
    "First tree based problem! Had a really annoying bug with files / directories that had the same name, so ended up overwriting parts of the tree. Blugh. Significant part of the work went into building the tree, I suppose I didn't really need to do that, just build the sizes as you go and don't duplicate contributions to the same parent...\n",
    "\n",
    "But that's waaaay less fun!\n",
    "\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "45053a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297683"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(7)\n",
    "\n",
    "\n",
    "def _group_commands(lines):\n",
    "    \"\"\"Convert lines into a command, arguments, and outputs\"\"\"\n",
    "    _, current_command, *args = lines[0].split(\" \")\n",
    "    outputs = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        if line.startswith(\"$\"):\n",
    "            yield (current_command, args), outputs\n",
    "            _, current_command, *args = line.split(\" \")\n",
    "            outputs = []\n",
    "        else:\n",
    "            outputs.append(tuple(line.split(\" \")))\n",
    "    yield (current_command, args), outputs\n",
    "\n",
    "\n",
    "def build_tree(output_lines):\n",
    "    \"\"\"Take input data and build a directory tree\"\"\"\n",
    "    node_lookup = {}\n",
    "\n",
    "    def dir_key(parent, dir_name):\n",
    "        if not parent:\n",
    "            return dir_name\n",
    "        return dir_key(parent.parent, parent.name) + \"/\" + dir_name\n",
    "\n",
    "    def cd(args, _, current_node, node_lookup):\n",
    "        new_dir = args[0]\n",
    "        if new_dir == \"..\":\n",
    "            return current_node.parent\n",
    "\n",
    "        key = dir_key(current_node, new_dir)\n",
    "        if key not in node_lookup:\n",
    "            node = Node(new_dir)\n",
    "            if current_node:\n",
    "                current_node.add_child(node)\n",
    "            node_lookup[key] = node\n",
    "\n",
    "        return node_lookup[key]\n",
    "\n",
    "    def ls(args, cmd_outputs, current_node, node_lookup):\n",
    "        for chunks in cmd_outputs:\n",
    "            if chunks[0] == \"dir\":\n",
    "                dirname = chunks[1]\n",
    "                key = dir_key(current_directory, dirname)\n",
    "\n",
    "                if key not in node_lookup:\n",
    "                    node_lookup[key] = Node(dirname)\n",
    "                    current_node.add_child(node_lookup[key])\n",
    "            else:\n",
    "                size, filename = chunks\n",
    "                current_node.add_child(Node(filename, int(size)))\n",
    "        return current_node\n",
    "\n",
    "    # execute all the commands\n",
    "    current_directory = None\n",
    "    for (cmd, args), outputs in _group_commands(output_lines):\n",
    "        if cmd == \"cd\":\n",
    "            command = cd\n",
    "        elif cmd == \"ls\":\n",
    "            command = ls\n",
    "        else:\n",
    "            raise Error(f\"Unknown command {cmd}\")\n",
    "        current_directory = command(args, outputs, current_directory, node_lookup)\n",
    "    return current_directory.root\n",
    "\n",
    "\n",
    "def get_sub_directory_sizes(tree):\n",
    "    sizes = defaultdict(int)\n",
    "\n",
    "    for node in visit_post_order(tree):\n",
    "        if not node.parent:\n",
    "            # is root, don't care\n",
    "            continue\n",
    "\n",
    "        if node.data is not None:\n",
    "            # contribute directly to the parent directory's size\n",
    "            sizes[node.parent] += node.data\n",
    "        else:\n",
    "            # we'll have visited all the children of sub-directories before,\n",
    "            # so use the cached result\n",
    "            sizes[node.parent] += sizes[node]\n",
    "\n",
    "    return sizes\n",
    "\n",
    "\n",
    "def sum_directories_below_limit(data):\n",
    "    tree = build_tree(data)\n",
    "    sizes = get_sub_directory_sizes(tree)\n",
    "\n",
    "    total = 0\n",
    "    for dirname, size in sizes.items():\n",
    "        if size <= 100000:\n",
    "            total += size\n",
    "    return total\n",
    "\n",
    "\n",
    "sum_directories_below_limit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "9abda55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1297683, \"Day 7.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea541c",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Now all the hard work of the first section is done, the second was pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "5c0a9e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5756764"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_smallest_directory_to_delete(data):\n",
    "    tree = build_tree(data)\n",
    "    directory_sizes = get_sub_directory_sizes(tree)\n",
    "\n",
    "    total_size = directory_sizes[tree]\n",
    "\n",
    "    remaining_space = 70000000 - total_size\n",
    "    required_space = 30000000\n",
    "\n",
    "    # start with the root node\n",
    "    smallest = tree\n",
    "    for node, size in directory_sizes.items():\n",
    "        if node.data is not None:\n",
    "            # is a file, skip\n",
    "            continue\n",
    "\n",
    "        if remaining_space + size > required_space:\n",
    "            if size < directory_sizes[smallest]:\n",
    "                smallest = node\n",
    "\n",
    "    return directory_sizes[smallest]\n",
    "\n",
    "\n",
    "find_smallest_directory_to_delete(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "4626d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 5756764, \"Day 7.2\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
