{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e25c7b-e8fd-4db3-aadf-5330412f6056",
   "metadata": {},
   "source": [
    "# [Advent of Code 2022](https://adventofcode.com/2022)\n",
    "<div align=\"right\"><i>Ben Emery<br>December 2022</i></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95016d62-abdf-4a62-9d2a-6a112387df02",
   "metadata": {},
   "source": [
    "## The toolbox\n",
    "\n",
    "Generalised pieces of code that either can be used in multiple questions or that simply makes understand the implementation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50b0928-2214-4276-87ae-09155de4c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from heapq import heappush, heappop\n",
    "import operator\n",
    "import re\n",
    "\n",
    "\n",
    "def Input(day, parser=str.strip, whole_file=False):\n",
    "    \"Fetch the data input from disk.\"\n",
    "    filename = f\"../data/advent2022/input{day}.txt\"\n",
    "    with open(filename) as fin:\n",
    "        if whole_file:\n",
    "            return parser(fin)\n",
    "        return mapt(parser, fin)\n",
    "\n",
    "\n",
    "def mapt(fn, *args):\n",
    "    \"Do a map, and convert the results to a tuple\"\n",
    "    return tuple(map(fn, *args))\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name, data=None):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self._children = []\n",
    "        self.parent = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Node name={self.name} parent={self.parent.name if self.parent else None} data={self.data}>\"\n",
    "\n",
    "    def add_child(self, node):\n",
    "        self._children.append(node)\n",
    "        node.parent = self\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return self._children[:]\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        if self.parent:\n",
    "            return self.parent.root\n",
    "        return self\n",
    "\n",
    "\n",
    "def visit_post_order(node: Node):\n",
    "    for child in node.children:\n",
    "        yield from visit_post_order(child)\n",
    "    yield node\n",
    "    \n",
    "\n",
    "def a_star(start, h_func, moves, cost=lambda s1, s2: 1):\n",
    "    \"\"\"A* implementation.\n",
    "\n",
    "    Finds the shortest sequence of states from to a goal (a state where\n",
    "    the hueristic function - h_func - is zero). We use a heap\n",
    "    as our priority queue, and processes those with the smallest\n",
    "    overall cost first (the cost of the path + the distance to target).\n",
    "\n",
    "    start:  the initial state to explore from\n",
    "    h_func: hueristic function that gives a \"distance\" to to target state,\n",
    "            when this is zero we're done.\n",
    "    moves:  function that generates all possible states from the supplied state\n",
    "            (these can go bakckwards, but will never be processed)\n",
    "    cost:   the cost of moving from ones state to another\n",
    "\n",
    "    return: list of states used to find the final state, wll raise an exception\n",
    "            if none was found.\n",
    "\n",
    "    \"\"\"\n",
    "    # The priority queue that we'll be reading from\n",
    "    queue = []\n",
    "    # We often care about the path taken, so persist the lowest costing path\n",
    "    # to each state\n",
    "    previous = {start: None}\n",
    "    # Lookup of state costs, we initialize at zero for the starting state\n",
    "    costs = {start: 0}\n",
    "\n",
    "    # Initialize our queue, this is ordered by path cost (f(n) = g(n) + h(n))\n",
    "    add_to_queue = lambda state: heappush(queue, (costs[state] + h_func(state), state))\n",
    "\n",
    "    # Recursively walk backwards to build the full path\n",
    "    get_path = (\n",
    "        lambda state: [] if state is None else get_path(previous[state]) + [state]\n",
    "    )\n",
    "\n",
    "    # Set the intial position and go!\n",
    "    add_to_queue(start)\n",
    "\n",
    "    while queue:\n",
    "        _, state = heappop(queue)\n",
    "        if h_func(state) == 0:\n",
    "            # We're done!\n",
    "            return get_path(state)\n",
    "\n",
    "        for new_state in moves(state):\n",
    "            new_cost = costs[state] + cost(state, new_state)\n",
    "\n",
    "            if new_state not in costs or new_cost < costs[new_state]:\n",
    "                # We've found a new state or a better path\n",
    "                costs[new_state] = new_cost\n",
    "                previous[new_state] = state\n",
    "                # We've modified our costs in some way, we need\n",
    "                # to explore from this state so add to the heap\n",
    "                add_to_queue(new_state)\n",
    "\n",
    "    # No solution was found\n",
    "    raise Exception(\"No solution for A* was discovered.\")\n",
    "\n",
    "    \n",
    "NEIGHBOUR4_DELTAS = (\n",
    "              ( 0, -1),\n",
    "    (-1,  0),           (1,  0),\n",
    "              ( 0,  1),\n",
    ")\n",
    "\n",
    "\n",
    "def neighbours4(x, y):\n",
    "    return tuple((x + dx, y + dy) for dx, dy in NEIGHBOUR4_DELTAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7ae6a-70a4-49cc-bf49-6cbdcbb148d5",
   "metadata": {},
   "source": [
    "## [Day 1](https://adventofcode.com/2022/day/1)\n",
    "\n",
    "Nothing too difficult for day 1, other than remembering how jupyter notebooks / python works...\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8eda8fa-37d2-4f95-8d5c-9864d5f34035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70296"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(1, lambda s: int(s) if s.strip() else None)\n",
    "\n",
    "def total_calories(data):\n",
    "    elves = [0]\n",
    "    for food in data:\n",
    "        if food is None:\n",
    "            elves.append(0)\n",
    "            continue\n",
    "        elves[-1] += food\n",
    "    return elves\n",
    "\n",
    "elves = total_calories(data)\n",
    "\n",
    "max(elves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9649e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 70296, \"Day 1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508cf0b-16c2-419a-a8f9-d62d833dcc85",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941ff200-913f-4963-8e94-971863e98de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205381"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elves.sort()\n",
    "sum(elves[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b830603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 205381, \"Day 1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c010a0",
   "metadata": {},
   "source": [
    "## [Day 2](https://adventofcode.com/2022/day/2)\n",
    "\n",
    "Again we're being eased in quite gently, unless you get dicts the wrong way around of course..\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534bc0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11449"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(2, lambda s: s.strip().split(\" \"))\n",
    "\n",
    "ROCK = \"R\"\n",
    "PAPER = \"P\"\n",
    "SCISSORS = \"S\"\n",
    "\n",
    "SCORES = {ROCK: 1, PAPER: 2, SCISSORS: 3}\n",
    "WINNING = {SCISSORS: ROCK, ROCK: PAPER, PAPER: SCISSORS}\n",
    "LOSING = dict((v, k) for k, v in WINNING.items())\n",
    "\n",
    "\n",
    "def map_hands(player_1, player_2):\n",
    "    map_1 = {\"A\": ROCK, \"B\": PAPER, \"C\": SCISSORS}\n",
    "    map_2 = {\"X\": ROCK, \"Y\": PAPER, \"Z\": SCISSORS}\n",
    "    return map_1[player_1], map_2[player_2]\n",
    "\n",
    "\n",
    "def score_game(p1, p2):\n",
    "    score = 3 if p1 == p2 else 0\n",
    "    if p2 == WINNING[p1]:\n",
    "        score = 6\n",
    "    return score + SCORES[p2]\n",
    "\n",
    "\n",
    "def score_all_games(data, hand_mapper):\n",
    "    hands = (map_hands(*d) for d in data)\n",
    "    return sum(score_game(*h) for h in hands)\n",
    "\n",
    "\n",
    "score_all_games(data, map_hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46691de",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 11449, \"Day 2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5a557",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac08e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_hands(player_1, player_2):\n",
    "    map_1 = {\"A\": \"R\", \"B\": \"P\", \"C\": \"S\"}\n",
    "    p1 = map_1[player_1]\n",
    "\n",
    "    if player_2 == \"X\":\n",
    "        p2 = LOSING[p1]\n",
    "    elif player_2 == \"Y\":\n",
    "        p2 = p1\n",
    "    elif player_2 == \"Z\":\n",
    "        p2 = WINNING[p1]\n",
    "\n",
    "    return p1, p2\n",
    "\n",
    "\n",
    "score_all_games(data, map_hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8085d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 13187, \"Day 2.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c233f",
   "metadata": {},
   "source": [
    "## [Day 3](https://adventofcode.com/2022/day/3)\n",
    "\n",
    "First time we need a set, membership tests are O(1) so they make sense to use here. Python makes it quite easy to extend behaviour for part 2, but I find I'm missing a more functional approach..\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a8ad04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7967"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(3)\n",
    "\n",
    "\n",
    "def split_halves(contents):\n",
    "    mid = int(len(contents) / 2)\n",
    "    return contents[:mid], contents[mid:]\n",
    "\n",
    "\n",
    "def find_common(*chunks):\n",
    "    common = set(chunks[0])\n",
    "    for chunk in chunks[1:]:\n",
    "        common &= set(chunk)\n",
    "    return tuple(common)\n",
    "\n",
    "\n",
    "def score(s):\n",
    "    ordinal = ord(s)\n",
    "    if ordinal > 96:\n",
    "        score = ordinal - ord(\"a\") + 1\n",
    "    else:\n",
    "        score = ordinal - ord(\"A\") + 26 + 1\n",
    "    return score\n",
    "\n",
    "\n",
    "def solve(all_data, grouper):\n",
    "    total = 0\n",
    "    for chunks in grouper(all_data):\n",
    "        common = find_common(*chunks)\n",
    "        total += score(common[0])\n",
    "    return total\n",
    "\n",
    "\n",
    "solve(data, lambda lines: map(split_halves, lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d811fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 7967, \"Day 3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feccd593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2716"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_threes(lines):\n",
    "    for idx in range(0, len(lines) - 1, 3):\n",
    "        yield lines[idx : idx + 3]\n",
    "\n",
    "\n",
    "solve(data, lambda lines: group_threes(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae31104",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2716, \"Day 3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf6a17",
   "metadata": {},
   "source": [
    "## [Day 4](https://adventofcode.com/2022/day/4)\n",
    "\n",
    "\n",
    "I quite enjoyed this one, refactoring the check for detecting supersets meant that I could solve the second part with little effort, which is useually the besy way to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c39d9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_line(line):\n",
    "    m = re.match(\"(\\d+)-(\\d+),(\\d+)-(\\d+)\", line)\n",
    "    a, b, c, d = m.groups()\n",
    "    return ((int(a), int(b)), (int(c), int(d)))\n",
    "\n",
    "\n",
    "data = Input(4, parse_line)\n",
    "\n",
    "\n",
    "def count_supersets(lines, is_within):\n",
    "    return sum(is_within(p1, p2) or is_within(p2, p1) for p1, p2 in lines)\n",
    "\n",
    "\n",
    "def contains_entirely(p1, p2):\n",
    "    return p1[0] >= p2[0] and p1[1] <= p2[1]\n",
    "\n",
    "\n",
    "count_supersets(data, contains_entirely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f042c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 453, \"Day 4.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed6340",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "687e1e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contains_partially(p1, p2):\n",
    "    return (p1[0] >= p2[0] and p1[0] <= p2[1]) or (p1[1] <= p2[1] and p1[1] >= p2[0])\n",
    "\n",
    "\n",
    "count_supersets(data, contains_partially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d12351ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 919, \"Day 4.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8409d",
   "metadata": {},
   "source": [
    "## [Day 5](https://adventofcode.com/2022/day/5)\n",
    "\n",
    "Today's felt like one of those puzzles where the hardest part was parsing the input! Reminding myself how python's regex matches works was fun though, and it's also a good lesson about something I've struggled with in the past: pragmatism. Parsing the data doesn't need to be dynamic, we can apply what we know from the inputs to help us out (that there are 9 stacks for example). In fancier language I'd say that we can use a heuristic to simplify things, but who needs that first thing in the morning?\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a8e8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LBLVVTVLP'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data(lines):\n",
    "    stacks = [[], [], [], [], [], [], [], [], []]\n",
    "    instructions = []\n",
    "\n",
    "    def add_to_stack(line):\n",
    "        for match in re.finditer(\"[A-Z]\", line):\n",
    "            stack = match.start() // 4\n",
    "            stacks[stack].insert(0, match.group())\n",
    "\n",
    "    def add_instruction(line):\n",
    "        move, pos_from, pos_to = mapt(int, re.findall(\"\\d+\", line))\n",
    "        instructions.append((move, pos_from - 1, pos_to - 1))\n",
    "\n",
    "    stacks_complete = False\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            stacks_complete = True\n",
    "            continue\n",
    "\n",
    "        if not stacks_complete:\n",
    "            add_to_stack(line)\n",
    "        else:\n",
    "            add_instruction(line)\n",
    "\n",
    "    return stacks, instructions\n",
    "\n",
    "\n",
    "data = Input(5, parse_data, whole_file=True)\n",
    "\n",
    "\n",
    "def single_mover(stacks, instruction):\n",
    "    move, pos_from, pos_to = instruction\n",
    "    for _ in range(move):\n",
    "        val = stacks[pos_from].pop()\n",
    "        stacks[pos_to].append(val)\n",
    "\n",
    "\n",
    "def follow_instructions(stacks, instructions, mover):\n",
    "    new_stacks = [s[:] for s in stacks]\n",
    "\n",
    "    for instruction in instructions:\n",
    "        mover(new_stacks, instruction)\n",
    "    return new_stacks\n",
    "\n",
    "\n",
    "def top_crates(stacks):\n",
    "    return \"\".join(s[-1] for s in stacks)\n",
    "\n",
    "\n",
    "stacks = follow_instructions(*data, single_mover)\n",
    "top_crates(stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2267eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == \"LBLVVTVLP\", \"Day 5.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9352d",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5edf5303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TPFFBDRJD'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bulk_mover(stacks, instruction):\n",
    "    move, pos_from, pos_to = instruction\n",
    "    stacks[pos_to].extend(stacks[pos_from][-move:])\n",
    "    stacks[pos_from] = stacks[pos_from][:-move]\n",
    "\n",
    "\n",
    "stacks = follow_instructions(*data, bulk_mover)\n",
    "top_crates(stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7261b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == \"TPFFBDRJD\", \"Day 5.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7939f58",
   "metadata": {},
   "source": [
    "## [Day 6](https://adventofcode.com/2022/day/6)\n",
    "\n",
    "Still nothing supuer difficult about this problem, using sets to track uniqueness may be a bit much, but given the size of the data it still returns instantly so why not!\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ece1ce20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(6)[0]\n",
    "\n",
    "\n",
    "def iter_chunks(data, n):\n",
    "    for i in range(0, len(data) - n):\n",
    "        yield i, data[i : i + n]\n",
    "\n",
    "\n",
    "def count_chars_to_packet(data, length=4):\n",
    "    for idx, chunk in iter_chunks(data, length):\n",
    "        if len(set(chunk)) == length:\n",
    "            break\n",
    "    chars_processed = idx + length\n",
    "    return chars_processed\n",
    "\n",
    "\n",
    "count_chars_to_packet(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fedbdb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1598, \"Day 6.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8bbbeb",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "656be743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2414"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_chars_to_packet(data, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35148529",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2414, \"Day 6.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41df8b",
   "metadata": {},
   "source": [
    "## [Day 7](https://adventofcode.com/2022/day/7)\n",
    "\n",
    "First tree based problem! Had a really annoying bug with files / directories that had the same name, so ended up overwriting parts of the tree. Blugh. Significant part of the work went into building the tree, I suppose I didn't really need to do that, just build the sizes as you go and don't duplicate contributions to the same parent...\n",
    "\n",
    "But that's waaaay less fun!\n",
    "\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e59f77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297683"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(7)\n",
    "\n",
    "\n",
    "def _group_commands(lines):\n",
    "    \"\"\"Convert lines into a command, arguments, and outputs\"\"\"\n",
    "    _, current_command, *args = lines[0].split(\" \")\n",
    "    outputs = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        if line.startswith(\"$\"):\n",
    "            yield (current_command, args), outputs\n",
    "            _, current_command, *args = line.split(\" \")\n",
    "            outputs = []\n",
    "        else:\n",
    "            outputs.append(tuple(line.split(\" \")))\n",
    "    yield (current_command, args), outputs\n",
    "\n",
    "\n",
    "def build_tree(output_lines):\n",
    "    \"\"\"Take input data and build a directory tree\"\"\"\n",
    "    node_lookup = {}\n",
    "\n",
    "    def dir_key(parent, dir_name):\n",
    "        if not parent:\n",
    "            return dir_name\n",
    "        return dir_key(parent.parent, parent.name) + \"/\" + dir_name\n",
    "\n",
    "    def cd(args, _, current_node, node_lookup):\n",
    "        new_dir = args[0]\n",
    "        if new_dir == \"..\":\n",
    "            return current_node.parent\n",
    "\n",
    "        key = dir_key(current_node, new_dir)\n",
    "        if key not in node_lookup:\n",
    "            node = Node(new_dir)\n",
    "            if current_node:\n",
    "                current_node.add_child(node)\n",
    "            node_lookup[key] = node\n",
    "\n",
    "        return node_lookup[key]\n",
    "\n",
    "    def ls(args, cmd_outputs, current_node, node_lookup):\n",
    "        for chunks in cmd_outputs:\n",
    "            if chunks[0] == \"dir\":\n",
    "                dirname = chunks[1]\n",
    "                key = dir_key(current_directory, dirname)\n",
    "\n",
    "                if key not in node_lookup:\n",
    "                    node_lookup[key] = Node(dirname)\n",
    "                    current_node.add_child(node_lookup[key])\n",
    "            else:\n",
    "                size, filename = chunks\n",
    "                current_node.add_child(Node(filename, int(size)))\n",
    "        return current_node\n",
    "\n",
    "    # execute all the commands\n",
    "    current_directory = None\n",
    "    for (cmd, args), outputs in _group_commands(output_lines):\n",
    "        if cmd == \"cd\":\n",
    "            command = cd\n",
    "        elif cmd == \"ls\":\n",
    "            command = ls\n",
    "        else:\n",
    "            raise Error(f\"Unknown command {cmd}\")\n",
    "        current_directory = command(args, outputs, current_directory, node_lookup)\n",
    "    return current_directory.root\n",
    "\n",
    "\n",
    "def get_sub_directory_sizes(tree):\n",
    "    sizes = defaultdict(int)\n",
    "\n",
    "    for node in visit_post_order(tree):\n",
    "        if not node.parent:\n",
    "            # is root, don't care\n",
    "            continue\n",
    "\n",
    "        if node.data is not None:\n",
    "            # contribute directly to the parent directory's size\n",
    "            sizes[node.parent] += node.data\n",
    "        else:\n",
    "            # we'll have visited all the children of sub-directories before,\n",
    "            # so use the cached result\n",
    "            sizes[node.parent] += sizes[node]\n",
    "\n",
    "    return sizes\n",
    "\n",
    "\n",
    "def sum_directories_below_limit(data):\n",
    "    tree = build_tree(data)\n",
    "    sizes = get_sub_directory_sizes(tree)\n",
    "\n",
    "    total = 0\n",
    "    for dirname, size in sizes.items():\n",
    "        if size <= 100000:\n",
    "            total += size\n",
    "    return total\n",
    "\n",
    "\n",
    "sum_directories_below_limit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a876628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1297683, \"Day 7.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90487838",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Now all the hard work of the first section is done, the second was pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "266a16be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5756764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_smallest_directory_to_delete(data):\n",
    "    tree = build_tree(data)\n",
    "    directory_sizes = get_sub_directory_sizes(tree)\n",
    "\n",
    "    total_size = directory_sizes[tree]\n",
    "\n",
    "    remaining_space = 70000000 - total_size\n",
    "    required_space = 30000000\n",
    "\n",
    "    # start with the root node\n",
    "    smallest = tree\n",
    "    for node, size in directory_sizes.items():\n",
    "        if node.data is not None:\n",
    "            # is a file, skip\n",
    "            continue\n",
    "\n",
    "        if remaining_space + size > required_space:\n",
    "            if size < directory_sizes[smallest]:\n",
    "                smallest = node\n",
    "\n",
    "    return directory_sizes[smallest]\n",
    "\n",
    "\n",
    "find_smallest_directory_to_delete(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bbcbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 5756764, \"Day 7.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21886c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b234129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1719"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Input(8, lambda s: mapt(int, s.strip()))\n",
    "\n",
    "\n",
    "def count_visible_tress(lines):\n",
    "    width = len(lines[0])\n",
    "    height = len(lines)\n",
    "\n",
    "    seen_trees = set()\n",
    "\n",
    "    # first pass, left to right and right to left\n",
    "    for y in range(1, height - 1):\n",
    "        left_min_tree = lines[y][0]\n",
    "        right_min_tree = lines[y][width - 1]\n",
    "\n",
    "        for x in range(1, width - 1):\n",
    "            if lines[y][x] > left_min_tree:\n",
    "                seen_trees.add((x, y))\n",
    "                left_min_tree = lines[y][x]\n",
    "            if lines[y][width - x - 1] > right_min_tree:\n",
    "                seen_trees.add((width - x - 1, y))\n",
    "                right_min_tree = lines[y][width - x - 1]\n",
    "\n",
    "    # second pass, top to bottom and bottom to top\n",
    "    for x in range(1, width - 1):\n",
    "        top_min_tree = lines[0][x]\n",
    "        bottom_min_tree = lines[height - 1][x]\n",
    "\n",
    "        for y in range(1, height - 1):\n",
    "            if lines[y][x] > top_min_tree:\n",
    "                seen_trees.add((x, y))\n",
    "                top_min_tree = lines[y][x]\n",
    "            if lines[height - y - 1][x] > bottom_min_tree:\n",
    "                seen_trees.add((x, height - y - 1))\n",
    "                bottom_min_tree = lines[height - y - 1][x]\n",
    "\n",
    "    perimiter = 2 * width + 2 * height - 4\n",
    "    return perimiter + len(seen_trees)\n",
    "\n",
    "\n",
    "count_visible_tress(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f78d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 1719"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75568c6e",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7d01e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590824"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_scenic_score(lines):\n",
    "    width = len(lines[0])\n",
    "    height = len(lines)\n",
    "\n",
    "    best_score = 0\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            tree = lines[y][x]\n",
    "\n",
    "            see_left = 0\n",
    "            for xl in range(x - 1, -1, -1):\n",
    "                if lines[y][xl] >= tree:\n",
    "                    see_left += 1\n",
    "                    break\n",
    "                see_left += 1\n",
    "\n",
    "            see_right = 0\n",
    "            for xr in range(x + 1, width):\n",
    "                if lines[y][xr] >= tree:\n",
    "                    see_right += 1\n",
    "                    break\n",
    "                see_right += 1\n",
    "\n",
    "            see_top = 0\n",
    "            for yt in range(y - 1, -1, -1):\n",
    "                if lines[yt][x] >= tree:\n",
    "                    see_top += 1\n",
    "                    break\n",
    "                see_top += 1\n",
    "\n",
    "            see_bottom = 0\n",
    "            for yb in range(y + 1, height):\n",
    "                if lines[yb][x] >= tree:\n",
    "                    see_bottom += 1\n",
    "                    break\n",
    "                see_bottom += 1\n",
    "\n",
    "            scenic_score = see_left * see_top * see_right * see_bottom\n",
    "            best_score = max(best_score, scenic_score)\n",
    "\n",
    "    return best_score\n",
    "\n",
    "\n",
    "get_scenic_score(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "932f36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 590824, \"Day 8.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c52cf3",
   "metadata": {},
   "source": [
    "## Day 9\n",
    "\n",
    "This one killed me! I could not for the life of me conceptualise what the movements were doing. Definitely glad this one is over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7698a1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6357"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_line(line):\n",
    "    chunks = line.split(\" \")\n",
    "    return chunks[0], int(chunks[1])\n",
    "\n",
    "\n",
    "def is_adjacent(p1, p2):\n",
    "    return max(abs(a - b) for a, b in zip(p1, p2)) <= 1\n",
    "\n",
    "\n",
    "def move_to_point(from_point, to_point):\n",
    "    fx, fy = from_point\n",
    "    tx, ty = to_point\n",
    "\n",
    "    # if not on the same plane, then step in that direction\n",
    "    move_point = lambda p1, p2: p1 if p1 == p2 else p1 + 1 if p1 < p2 else p1 - 1\n",
    "\n",
    "    x = move_point(fx, tx)\n",
    "    y = move_point(fy, ty)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def follow_motions(motions, rope_length=2):\n",
    "    ropes = [(0, 0) for _ in range(rope_length)]\n",
    "\n",
    "    deltas = {\"R\": (1, 0), \"D\": (0, -1), \"L\": (-1, 0), \"U\": (0, 1)}\n",
    "\n",
    "    add_points = lambda p1, p2: tuple(a + b for a, b in zip(p1, p2))\n",
    "\n",
    "    def step(direction, ropes):\n",
    "        head_pos = ropes[0]\n",
    "        dx, dy = deltas[direction]\n",
    "        x, y = head_pos\n",
    "        new_head_pos = (x + dx, y + dy)\n",
    "\n",
    "        new_positions = [new_head_pos]\n",
    "        for tail in ropes[1:]:\n",
    "            target = new_positions[-1]\n",
    "            if is_adjacent(tail, target):\n",
    "                # within distance, no need to move\n",
    "                new_positions.append(tail)\n",
    "                continue\n",
    "\n",
    "            new_tail_pos = move_to_point(tail, target)\n",
    "            new_positions.append(new_tail_pos)\n",
    "        return new_positions\n",
    "\n",
    "    for direction, amount in motions:\n",
    "        for _ in range(amount):\n",
    "            ropes = step(direction, ropes)\n",
    "            yield ropes\n",
    "\n",
    "\n",
    "def count_unique_locations(motions, rope_length=2):\n",
    "    visited = set()\n",
    "    for rope in follow_motions(motions, rope_length):\n",
    "        *_, tail_pos = rope\n",
    "        visited.add(tail_pos)\n",
    "    return len(visited)\n",
    "\n",
    "\n",
    "data = Input(9, parse_line)\n",
    "count_unique_locations(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1d3382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 6357, \"Day 9.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9ccb26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2627"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_unique_locations(data, rope_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2062094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 2627, \"Day 9.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c49cf8",
   "metadata": {},
   "source": [
    "## Day 10\n",
    "\n",
    "This was quite fun, making use of python's generators to suspend execution meant that I could simulate the clock cycles quite nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "593e9cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13760"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_line(line):\n",
    "    cmd, *args = line.strip().split(' ')\n",
    "    if cmd == \"addx\":\n",
    "        return cmd, int(args[0])\n",
    "    return cmd, args\n",
    "\n",
    "instructions = Input(10, parse_line)\n",
    "\n",
    "def perform_instructions(instructions):\n",
    "    # init the \"reigister\"\n",
    "    x = 1\n",
    "    for ins, *args in instructions:\n",
    "        if ins == \"noop\":\n",
    "            yield x\n",
    "        elif ins == \"addx\":\n",
    "            value = args[0]\n",
    "            yield x\n",
    "            x += value\n",
    "            yield x\n",
    "\n",
    "            \n",
    "def sum_signal_strength(instructions):\n",
    "    total = 0\n",
    "    for executed_instruction_idx, x in enumerate(perform_instructions(instructions), 1):\n",
    "        current_cycle = executed_instruction_idx + 1\n",
    "        if (current_cycle - 20) % 40 == 0:\n",
    "            total += current_cycle * x\n",
    "    return total\n",
    "\n",
    "            \n",
    "sum_signal_strength(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e74d5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 13760, \"Day 10.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b62edd",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "It's always quite fun when there's some ascii art invovled :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db49d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##  #### #  # ####  ##  ###  #### #### \n",
      "#  # #    # #     # #  # #  # #    #    \n",
      "#  # ###  ##     #  #    #  # ###  ###  \n",
      "###  #    # #   #   #    ###  #    #    \n",
      "# #  #    # #  #    #  # #    #    #    \n",
      "#  # #    #  # ####  ##  #    #### #    \n"
     ]
    }
   ],
   "source": [
    "def draw_sprite(instructions):\n",
    "    # not in the puzzle, but easier to read\n",
    "    OFF_CHAR = \" \"\n",
    "    ON_CHAR = \"#\"\n",
    "    WIDTH = 40\n",
    "    HEIGHT = 6\n",
    "    rows = [[OFF_CHAR] * WIDTH for _ in range(HEIGHT)]\n",
    "\n",
    "    for executed_instruction_idx, x in enumerate(perform_instructions(instructions), 1):\n",
    "        row_being_drawn = executed_instruction_idx // WIDTH\n",
    "        pixel_being_drawn = executed_instruction_idx % WIDTH\n",
    "\n",
    "        if x >= pixel_being_drawn - 1 and x <= pixel_being_drawn + 1:\n",
    "            rows[row_being_drawn][pixel_being_drawn] = ON_CHAR\n",
    "\n",
    "    print(\"\\n\".join(\"\".join(r) for r in rows))\n",
    "\n",
    "\n",
    "draw_sprite(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d8b94",
   "metadata": {},
   "source": [
    "## Day 11\n",
    "\n",
    "Well this one was interesting, I've been bitten by the Chinese Remainder Theorem before, so spent a bit of time in the write up for part 2 below.\n",
    "\n",
    "There's some abose of python's `operator` library below which I'm not super happy about, but it'll do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "077dc43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50616"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_input(lines):\n",
    "    monkeys = []\n",
    "    ops = {\"+\": operator.add, \"*\": operator.mul}\n",
    "\n",
    "    def get_new_func(operation, operation_value):\n",
    "        if operation_value == \"old\":\n",
    "            return lambda val: ops[operation](val, val)\n",
    "        return lambda val: ops[operation](val, int(operation_value))\n",
    "\n",
    "    # we're given a file input to parse, read all the lines and clear new line chars\n",
    "    lines = [l.strip() for l in lines]\n",
    "    for idx in range(0, len(lines), 7):\n",
    "        starting_items = [int(d) for d in re.findall(\"\\d+\", lines[idx + 1])]\n",
    "\n",
    "        *_, operation, operation_new = lines[idx + 2].split(\" \")\n",
    "\n",
    "        test_modulo = int(lines[idx + 3].split(\" \")[-1])\n",
    "        test_true_result = int(lines[idx + 4].split(\" \")[-1])\n",
    "        test_false_result = int(lines[idx + 5].split(\" \")[-1])\n",
    "\n",
    "        monkeys.append(\n",
    "            {\n",
    "                \"starting_items\": starting_items,\n",
    "                \"get_new_worry\": get_new_func(operation, operation_new),\n",
    "                \"test_modulo\": test_modulo,\n",
    "                \"true_monkey\": test_true_result,\n",
    "                \"false_monkey\": test_false_result,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return monkeys\n",
    "\n",
    "\n",
    "data = Input(11, parse_input, whole_file=True)\n",
    "\n",
    "\n",
    "def fast_monkey_business(monkeys, round_count=20, apply_reduction=True):\n",
    "    # clone the starting items as we mutate them in place\n",
    "    starting_items = dict(\n",
    "        (idx, m[\"starting_items\"][:]) for idx, m in enumerate(monkeys)\n",
    "    )\n",
    "    counter = dict((idx, 0) for idx in range(len(monkeys)))\n",
    "\n",
    "    # we know that the modulos are coprime, so we can safely reduce large modulos by their\n",
    "    # lowest multiple, see text below for explanation\n",
    "    module_multiple = reduce(operator.mul, [m[\"test_modulo\"] for m in monkeys])\n",
    "    # crt == chinese remainder theorem\n",
    "    apply_crt = lambda worry: worry % module_multiple\n",
    "\n",
    "    reduce_worry = apply_crt\n",
    "\n",
    "    if apply_reduction:\n",
    "        reduce_worry = lambda worry: worry // 3\n",
    "\n",
    "    for _ in range(round_count):\n",
    "        for idx, monkey in enumerate(monkeys):\n",
    "            while starting_items[idx]:\n",
    "                item = starting_items[idx].pop(0)\n",
    "                new_worry = monkey[\"get_new_worry\"](item)\n",
    "                new_level = reduce_worry(new_worry)\n",
    "\n",
    "                if new_level % monkey[\"test_modulo\"] == 0:\n",
    "                    new_target = monkey[\"true_monkey\"]\n",
    "                else:\n",
    "                    new_target = monkey[\"false_monkey\"]\n",
    "                starting_items[new_target].append(new_level)\n",
    "\n",
    "                counter[idx] += 1\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "def find_busiest_monkeys(*args, **kwargs):\n",
    "    counter = fast_monkey_business(*args, **kwargs)\n",
    "    a, b = sorted(counter.values())[-2:]\n",
    "    return a * b\n",
    "\n",
    "\n",
    "find_busiest_monkeys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "823ed1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 50616, \"Day 11.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c998c1",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "We're warned that the brute force of the first part won't work for the second, as the step of divising by 3 on line 47 is going away, and need to do something else.\n",
    "\n",
    "Looking at the Test divisors from the input (5, 2, 13, 19, 11, 3, 7, 17), we can see that they are all prime, and thus have a greatest common divisor (GCD) of 1.\n",
    "\n",
    "This means we can use the [Chinese Remainder Theorm](https://en.wikipedia.org/wiki/Chinese_remainder_theorem). \n",
    "\n",
    "...but what does that _mean_.\n",
    "\n",
    "We know we need to perform several rounds of `X mod(y)`, but what happens if `X` is much, much larger than `y`? The operation becomes really really slow, it'd be nice if we could use a larger number to mod it against. As were dealing with modulo arithmitic, it's worth reminding oursleves (as I had to..) that `X mod(y)` is the same as `X mod(y * C) mod(y)` for _any_ C. i.e.\n",
    "\n",
    "```\n",
    "1345 mod(19) = 15\n",
    "1345 mod(19 * 2) mod(19) = 15 mod (19) = 15\n",
    "1345 mod(19 * 3) mod(19) = 34 mod (19) = 15\n",
    "```\n",
    "\n",
    "As we know that all our modulos do _not share a common factor_ then their multiple will be a large number that is the lowest common multiple of all of them. So taking the first three examples I've shown above:\n",
    "\n",
    "```\n",
    "1345 mod(2) = 1\n",
    "1345 mod(2 * 3 * 19) mod(2) = 91 mod(2) = 1\n",
    "\n",
    "1345 mod(3) = 1\n",
    "1345 mod(2 * 3 * 19) mod(4) = 91 mod(3) = 1\n",
    "\n",
    "1345 mod(19) = 15\n",
    "1345 mod(2 * 3 * 19) mod(19) = 91 mod(15) = 15\n",
    "\n",
    "```\n",
    "\n",
    "Hopefully that's a useful example of how the CRT works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f44e722f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11309046332"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I just refactored the code in part one..\n",
    "find_busiest_monkeys(data, 10_000, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af617e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 11309046332, \"Day 11.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc860af",
   "metadata": {},
   "source": [
    "## Day 12\n",
    "\n",
    "First breadth first search! I've just cracked out an A* implementation I wrote a few years ago, but it's always such a joy to use. A* is such an elegant algorithm, I love it!\n",
    "\n",
    "For some extra fun, someone made a simulation of their solution in [minecraft](https://www.reddit.com/r/adventofcode/comments/zjsgaa/2022_day_12_part_2_in_minecraft/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65fe2d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all_cells(cell, grid):\n",
    "    for y, row in enumerate(grid):\n",
    "        try:\n",
    "            x = row.index(cell)\n",
    "            yield x, y\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def find_cell(cell, grid):\n",
    "    return next(find_all_cells(cell, grid))\n",
    "\n",
    "\n",
    "def find_destination_position(grid):\n",
    "    END_CELL = \"E\"\n",
    "    return find_cell(END_CELL, grid)\n",
    "\n",
    "\n",
    "def find_start_position(grid):\n",
    "    START_CELL = \"S\"\n",
    "    return find_cell(START_CELL, grid)\n",
    "\n",
    "\n",
    "def fewest_steps(grid, start, destination):\n",
    "    def normalise_grid(grid):\n",
    "        rows = []\n",
    "        for row in grid:\n",
    "            new_row = []\n",
    "            for cell in row:\n",
    "                if cell == \"S\":\n",
    "                    new_row.append(0)\n",
    "                    continue\n",
    "                if cell == \"E\":\n",
    "                    new_row.append(ord(\"z\") - ord(\"a\"))\n",
    "                    continue\n",
    "                new_row.append(ord(cell) - ord(\"a\"))\n",
    "            rows.append(new_row)\n",
    "        return rows\n",
    "\n",
    "    grid_as_numbers = normalise_grid(grid)\n",
    "\n",
    "    Y_LIMIT = len(grid) - 1\n",
    "    X_LIMIT = len(grid[0]) - 1\n",
    "\n",
    "    def h_func(state):\n",
    "        \"\"\"Cost function is manhatten distance from destination.\"\"\"\n",
    "        return abs(state[0] - destination[0]) + abs(state[1] - destination[1])\n",
    "\n",
    "    def moves(state):\n",
    "        x, y = state\n",
    "        current_cell = grid_as_numbers[y][x]\n",
    "\n",
    "        for (\n",
    "            nx,\n",
    "            ny,\n",
    "        ) in neighbours4(x, y):\n",
    "            if nx < 0 or ny < 0 or nx > X_LIMIT or ny > Y_LIMIT:\n",
    "                continue\n",
    "\n",
    "            new_cell = grid_as_numbers[ny][nx]\n",
    "            if new_cell - current_cell > 1:\n",
    "                # can't climb UP more than one, but can go down\n",
    "                continue\n",
    "\n",
    "            yield nx, ny\n",
    "\n",
    "    shortest_path = a_star(start, h_func, moves)\n",
    "    return len(shortest_path) - 1\n",
    "\n",
    "\n",
    "def fewest_steps_fixed_start(grid):\n",
    "    start = find_start_position(grid)\n",
    "    destination = find_destination_position(grid)\n",
    "    return fewest_steps(grid, start, destination)\n",
    "\n",
    "\n",
    "data = Input(12)\n",
    "fewest_steps_fixed_start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29b929ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 423, \"Day 12.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa0e8a",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff1b2bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fewest_steps_lowest_start(grid):\n",
    "    destination = find_destination_position(grid)\n",
    "    start_positions = find_all_cells(\"a\", grid)\n",
    "    return min(fewest_steps(grid, start, destination) for start in start_positions)\n",
    "\n",
    "\n",
    "fewest_steps_lowest_start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afd668d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _ == 416, \"Day 12.2\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
