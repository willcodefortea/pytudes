{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Advent of Code - 2017](https://adventofcode.com/2017)\n",
    "\n",
    "Advent of code is a puzzle solving website, two puzzles released for each day of advent (Dec 1st - Dec 25th). If previous years are anything to go by the cover a large variety of algorithms and are generally quite fun!\n",
    "\n",
    "Each year the puzzels are built around a central theme, with this year's theme being that we have been \"digitized\" into a computer, and must solve various problems from inside the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 0\n",
    "\n",
    "This portion contains various common pieces of code that'll be used on multiple days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict, deque\n",
    "from functools import reduce\n",
    "from itertools import cycle, count, islice\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "cat = ''.join\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "        \n",
    "def tail(n, iterable):\n",
    "    \"Return an iterator over the last n items\"\n",
    "    # tail(3, 'ABCDEFG') --> E F G\n",
    "    return iter(deque(iterable, maxlen=n))\n",
    "\n",
    "\n",
    "def head(n, iterable):\n",
    "    \"\"\"Return an iterator over the first n items.\"\"\"\n",
    "    return iter(islice(iterable, n))\n",
    "\n",
    "\n",
    "def nth_item(n, iterable):\n",
    "    \"\"\"Take the nth item from an iterator.\"\"\"\n",
    "    return next(islice(iterable, n, n + 1))\n",
    "\n",
    "\n",
    "def last(iterable):\n",
    "    \"\"\"Returns the final item in an iterable.\"\"\"\n",
    "    return next(tail(1, iterable))\n",
    "\n",
    "\n",
    "def first(iterable, n=1):\n",
    "    return islice(iterable, n)\n",
    "\n",
    "\n",
    "def Input(day):\n",
    "    \"\"\"Fetch the data input from disk.\"\"\"\n",
    "    filename = os.path.join('../data/advent2017/input{}.txt'.format(day))\n",
    "    return open(filename)\n",
    "\n",
    "\n",
    "def neighbours4(x, y):\n",
    "    return (x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)\n",
    "\n",
    "\n",
    "def neighbours8(x, y):\n",
    "    return (\n",
    "        (x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1),\n",
    "        (x - 1, y - 1), (x - 1, y + 1), (x + 1, y - 1), (x + 1, y + 1)\n",
    "    )\n",
    "\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    return sum(\n",
    "        abs(a - b) for a, b in zip(point1, point2)\n",
    "    )\n",
    "\n",
    "# TREES\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self._children = []\n",
    "        self.parent = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '<Node 0x:{} name={}>'.format(\n",
    "            id(self),\n",
    "            self.name\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def children(self):\n",
    "        \"\"\"Immutable set of the node's children.\"\"\"\n",
    "        return tuple(self._children)\n",
    "    \n",
    "    def add_child(self, child):\n",
    "        self._children.append(child)\n",
    "    \n",
    "    def remove_child(self, child):\n",
    "        self._children.remove(child)\n",
    "    \n",
    "    def add_parent(self, parent):\n",
    "        if self.parent:\n",
    "            self.parent.remove_child(self)\n",
    "\n",
    "        self.parent = parent\n",
    "\n",
    "        if self.parent:\n",
    "            self.parent.add_child(self)\n",
    "    \n",
    "    @property\n",
    "    def root(self):\n",
    "        if not self.parent:\n",
    "            return self\n",
    "        return self.parent.root\n",
    "    \n",
    "    @property\n",
    "    def decendants(self):\n",
    "        \"\"\"Visit all children.\"\"\"\n",
    "        iterator = visit_pre_order(self)\n",
    "        # Skip this node\n",
    "        next(iterator)\n",
    "        return iterator\n",
    "    \n",
    "    @property\n",
    "    def siblings(self):\n",
    "        for child in self.parent.children:\n",
    "            if child == self:\n",
    "                continue\n",
    "            yield child\n",
    "\n",
    "    \n",
    "def visit_pre_order(node):\n",
    "    \"\"\"Visit a Tree in pre-order.\n",
    "    \n",
    "      A\n",
    "     / \\\n",
    "    B   C\n",
    "    \n",
    "    A -> B -> C\n",
    "    \"\"\"\n",
    "    yield node\n",
    "    for child in node.children:\n",
    "        yield from visit_pre_order(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 1: Inverse Captcha](https://adventofcode.com/2017/day/1)\n",
    "\n",
    "We're greeted by a door, and must proove that we are _not_ human to continue. The first puzzle has us performing a captha that \"only a computer\" can solve. We're required to sum digits in a list where each digit matches the one immediately following it, wrapping to the start if we overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_if_match(nums, jump_distance):\n",
    "    total = 0\n",
    "    for index, n in enumerate(nums):\n",
    "        next_n = nums[(index + jump_distance) % len(nums)] \n",
    "        if n == next_n:\n",
    "            total += n\n",
    "    return total\n",
    "\n",
    "def sum_consecutive(data):\n",
    "    nums = list(map(int, data))\n",
    "    jump_distance = 1\n",
    "    return sum_if_match(nums, jump_distance)\n",
    "\n",
    "\n",
    "assert sum_consecutive('1122') == 3\n",
    "assert sum_consecutive('1111') == 4\n",
    "assert sum_consecutive('1234') == 0\n",
    "assert sum_consecutive('91212129') == 9\n",
    "\n",
    "sum_consecutive(Input(1).read().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second portion, we're again summing digits, but now only if we match the digit exactly _half the list_ away. At this point we can modify the initial code and provide a jump distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_half(data):\n",
    "    nums = list(map(int, data))\n",
    "    jump_distance = len(nums) // 2\n",
    "    return sum_if_match(nums, jump_distance)\n",
    "    \n",
    "\n",
    "assert sum_half('1212') == 6\n",
    "assert sum_half('1221') == 0\n",
    "assert sum_half('123425') == 4\n",
    "assert sum_half('123123') == 12\n",
    "assert sum_half('12131415') == 4\n",
    "\n",
    "sum_half(Input(1).read().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 2: Corruption Checksum](https://adventofcode.com/2017/day/2)\n",
    "\n",
    "Here we're required to perform some data anaylsis on a spreadsheet calculating a checksum of each row by finding the difference of the max and min values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(data):\n",
    "    as_ints = []\n",
    "    for row in data.split('\\n'):\n",
    "        if not row:\n",
    "            break\n",
    "        nums = list(map(int, re.findall('\\d+', row)))\n",
    "        as_ints.append(nums)\n",
    "    return as_ints\n",
    "\n",
    "\n",
    "data = parse_input(Input(2).read())\n",
    "\n",
    "sum((max(row) - min(row) for row in data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second portion requires us to find pairs of number in each row that are evenly divisible, and summing the result of their division. As we don't know in which order the pair will appear, I sort each row when meeting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_even_div(data):\n",
    "    total = 0\n",
    "    for nums in data:\n",
    "        nums = sorted(nums)\n",
    "        for i, x in enumerate(nums[:-1]):\n",
    "            for y in nums[i + 1:]:\n",
    "                if y % x == 0:\n",
    "                    total += y // x\n",
    "                    break\n",
    "    return total\n",
    "\n",
    "\n",
    "sum_even_div(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 3: Spiral Memory](https://adventofcode.com/2017/day/3)\n",
    "\n",
    "We need to find the coordinate of an number when it's displayed in a spiral format. I.e.\n",
    "\n",
    "```\n",
    "17  16  15  14  13\n",
    "18   5   4   3  12\n",
    "19   6   1   2  11\n",
    "20   7   8   9  10\n",
    "21  22  23---> ...\n",
    "```\n",
    "\n",
    "I started this problem by working out an equation to find the location of the Nth element, without building the rest of the grid. While this worked well for the first part of the problem, the second part requires us to build a spiral grid anyway! (It's much smaller, but still.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coorindates(N):\n",
    "    \"\"\"Find the coordinates of N in a spiral matrix.\n",
    "    \n",
    "    We can find the shell that the number occurs in by\n",
    "    finding the upper limit for each shell and \n",
    "    \"\"\"\n",
    "    # First find the shell that the number appears in\n",
    "    # number of elements in each shell is 4*(n-1)\n",
    "    if N == 1:\n",
    "        return 0, 0\n",
    "\n",
    "    shell = 1\n",
    "    shell_size = 1\n",
    "    while N > shell_size ** 2:\n",
    "        shell += 1\n",
    "        shell_size += 2\n",
    "\n",
    "    shell_end = shell_size ** 2\n",
    "    shell_start = (shell_size - 2) ** 2\n",
    "    elms_in_shell = shell_end - shell_start\n",
    "    position_in_shell = N - shell_start\n",
    "    \n",
    "    side_length = elms_in_shell // 4\n",
    "    half_side = side_length // 2\n",
    "    \n",
    "    side = position_in_shell / elms_in_shell\n",
    "    \n",
    "    if side <= 0.25:\n",
    "        # right\n",
    "        x = half_side\n",
    "        y = (position_in_shell % side_length) - half_side\n",
    "    elif side <= 0.5:\n",
    "        # top\n",
    "        x = (position_in_shell % side_length) - half_side\n",
    "        y = half_side\n",
    "    elif side <= 0.75:\n",
    "        # left\n",
    "        x = -half_side\n",
    "        y = (position_in_shell % side_length) - half_side\n",
    "    else:\n",
    "        # bottom\n",
    "        x = (position_in_shell % side_length) - half_side\n",
    "        y = -half_side\n",
    "    return (x, y)\n",
    "    \n",
    "    \n",
    "def carry_distance(N):\n",
    "    x, y = find_coorindates(N)\n",
    "    return manhattan_distance((0, 0), (x, y))\n",
    "\n",
    "\n",
    "data = 312051\n",
    "assert carry_distance(1) == 0\n",
    "assert carry_distance(12) == 3\n",
    "assert carry_distance(23) == 2\n",
    "assert carry_distance(1024) == 31\n",
    "carry_distance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part requires us to perform a \"stress test\" to populate a spiral grid with values the sum of all adjacent cells in the grid. As we don't know the upper bound (and I don't know how to initialize an infinite grid that can be referenced arbitarily..) I went with a dictionay to store point references and their values. \n",
    "\n",
    "By combining two infinite generators that cycle through the directions we turn and the distances we need to travel, we build an a third infinite generator that contains all the steps we'll take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle, count\n",
    "\n",
    "def spiral_distances():\n",
    "    \"\"\"\"Yields 1, 1, 2, 2, 3, 3, ...\n",
    "    \n",
    "    As the spiral wraps around itself, we increase\n",
    "    the distance we travel by 1 every two distances.\n",
    "    \n",
    "    This is because every 2 distances we're moving in\n",
    "    the opposite direction, so to we increase the\n",
    "    distance to ensure we can move past the movement\n",
    "    we're now opposing.\n",
    "    \"\"\"\n",
    "    for distance in count(1):\n",
    "        yield distance\n",
    "        yield distance\n",
    "\n",
    "            \n",
    "def directions():\n",
    "    \"\"\"Yields R, U, L, D, R, U, L, D, ...\"\"\"\n",
    "    up = (0, -1)\n",
    "    down = (0, 1)\n",
    "    left = (-1, 0)\n",
    "    right = (1, 0)\n",
    "    return cycle((right, up, left, down))\n",
    "\n",
    "\n",
    "def spiral_movements():\n",
    "    for distance, direction in zip(spiral_distances(), directions()):\n",
    "        for _ in range(distance):\n",
    "            yield direction\n",
    "\n",
    "\n",
    "def stress_test(max_val):\n",
    "    grid = {}\n",
    "    x, y = 0, 0\n",
    "    grid[(x, y)] = 1\n",
    "    for direction in spiral_movements():\n",
    "        dx, dy = direction\n",
    "        x += dx\n",
    "        y += dy\n",
    "        val = sum(\n",
    "            grid.get(neighbour, 0)\n",
    "            for neighbour in neighbours8(x, y)\n",
    "        )\n",
    "\n",
    "        grid[(x, y)] = val\n",
    "\n",
    "        if val > max_val:\n",
    "            return val\n",
    "stress_test(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 4: High-Entropy Passphrases](https://adventofcode.com/2017/day/4)\n",
    "\n",
    "W're tasked with checking the validity of a series of passphrases. A passphrase is considered valid if each word within the passphrase is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(passphrase):\n",
    "    words = re.findall('\\w+', passphrase)\n",
    "    unique = set(words)\n",
    "    return len(unique) == len(words)\n",
    "\n",
    "def valid_passphrases(data):\n",
    "    return sum(\n",
    "        is_valid(passphrase)\n",
    "        for passphrase in data.split('\\n')\n",
    "    )\n",
    "    \n",
    "\n",
    "valid_passphrases(Input(4).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part two requires us to ensure that no anagrams are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(passphrase):\n",
    "    words = re.findall('\\w+', passphrase)\n",
    "    unique = set(\n",
    "        cat(sorted(w)) for w in words\n",
    "    )\n",
    "    return len(unique) == len(words)\n",
    "\n",
    "assert not is_valid('abcde xyz ecdab')\n",
    "\n",
    "valid_passphrases(Input(4).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 5: A Maze of Twisty Trampolines, All Alike](https://adventofcode.com/2017/day/5)\n",
    "\n",
    "In this example we're following a series of jump instructions through an list that modify the jump distance once it's been performed. For each item in the list, `n`, we jump `n` steps away and increment the jump value in at that index by 1.\n",
    "\n",
    "Originally I didn't have the `increment_by` as a callable, and in doing so the program is noticably slowed (part two went from 7s to 9s), however it makes the second part trivial so I introduced it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def follow_instructions(data, increment_by=lambda n: 1):\n",
    "    instructions = list(map(int, re.findall('-?\\d+', data)))\n",
    "    step_count = 0\n",
    "    index = 0\n",
    "    while True:\n",
    "        try:\n",
    "            jump = instructions[index]\n",
    "        except IndexError:\n",
    "            break\n",
    "        instructions[index] += increment_by(jump)\n",
    "        index += jump\n",
    "        step_count += 1\n",
    "    return step_count\n",
    "\n",
    "test_input = \"\"\"\n",
    "0\n",
    "3\n",
    "0\n",
    "1\n",
    "-3\n",
    "\"\"\"\n",
    "assert follow_instructions(test_input) == 5\n",
    "\n",
    "% time follow_instructions(Input(5).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part is the same as the first but this time we decrement the jump value if it's `>= 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increment_by = lambda n: -1 if n > 2 else 1\n",
    "assert follow_instructions(test_input, increment_by) == 10\n",
    "% time follow_instructions(Input(5).read(), increment_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 6: Memory Reallocation](https://adventofcode.com/2017/day/6)\n",
    "\n",
    "We're tasked re-bucketing data, and dedecting any cyclical allocations. Given N buckets, take the maximum, set that bucket to zero and then add one for N to each other bucket in order, wrapping to the start.\n",
    "\n",
    "i.e.\n",
    "\n",
    "```\n",
    "    (0, 2, 7, 0) Initial state, 7 is highest so set to zero and distribute\n",
    "    (2, 4, 1, 2) 4 is now the highest\n",
    "    (3, 1, 2, 3) We have two threes, the first takes precedence\n",
    "    (0, 2, 3, 4) 4 is now the hightest\n",
    "    (1, 3, 4, 1) 4 again wins\n",
    "    (2, 4, 1, 2) *LOOP* We've seen this state before, and was detected on the 5th step.\n",
    "```\n",
    "\n",
    "As I'm generating this data as we go, I don't think there's any nifty algorithms that we can implement to detect a loop. Instead I just keep track of what's been seen and compare the current state.\n",
    "\n",
    "As we want to use a set to keep track of what we've seen there's a lot of conversion between lists and tuples, but this is a smaller trade off as the seen list can get quite large, so [O(1) member test compared to O(N)](https://wiki.python.org/moin/TimeComplexity) wins! (Using a list here takes ~20 times longer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redistribute_memory(banks):\n",
    "    seen = set()\n",
    "    \n",
    "    for cycle in count(1):\n",
    "        if banks in seen:\n",
    "            break\n",
    "        seen.add(banks)\n",
    "        banks = redistribute(banks)\n",
    "    return cycle - 1\n",
    "\n",
    "\n",
    "def redistribute(banks):\n",
    "    banks = list(banks)\n",
    "    blocks = max(banks)\n",
    "    max_index = banks.index(blocks)\n",
    "    \n",
    "    banks[max_index] = 0\n",
    "    \n",
    "    offset = max_index + 1\n",
    "    addition = blocks // len(banks)\n",
    "    extra_lim = blocks % len(banks)\n",
    "    \n",
    "    for i in range(len(banks)):\n",
    "        idx = (offset + i) % len(banks)\n",
    "        banks[idx] += addition\n",
    "        if i < extra_lim:\n",
    "            banks[idx] += 1\n",
    "    return tuple(banks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert redistribute((0, 2, 7, 0)) == (2, 4, 1, 2)\n",
    "assert redistribute_memory((0, 2, 7, 0)) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks = tuple(\n",
    "    int(num)\n",
    "    for num in re.findall('\\d+', Input(6).read())\n",
    ")\n",
    "redistribute_memory(banks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part two we need to know the length of the loop. We can do this by keeping track of the original index of each memory bank and compare it to the index we're on when we reach the final bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redistribute_memory2(banks):\n",
    "    seen = {}\n",
    "    \n",
    "    for cycle in count(1):\n",
    "        if banks in seen:\n",
    "            break\n",
    "        seen[banks] = cycle\n",
    "        banks = redistribute(banks)\n",
    "    return cycle - seen[banks] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redistribute_memory2(banks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 7: Recursive Circus](http://adventofcode.com/2017/day/7)\n",
    "\n",
    "Here we meet our first tree. This could probably be solved without such large data structures, but this may come up later so I think it's worth investing time into now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedNode(Node):\n",
    "    def __init__(self, name, weight):\n",
    "        self.weight = weight\n",
    "        super().__init__(name)\n",
    "        \n",
    "    @property\n",
    "    def decendant_weight(self):\n",
    "        return sum(child.weight for child in self.decendants)\n",
    "    \n",
    "    @property\n",
    "    def total_weight(self):\n",
    "        return self.weight + self.decendant_weight\n",
    "\n",
    "\n",
    "def parse_input(data):\n",
    "    chunks = re.findall(\"(\\w+) \\((\\d+)\\)(?: -> ([a-z, ]+))?\", data)\n",
    "    \n",
    "    nodes = {\n",
    "        name: WeightedNode(name, int(weight))\n",
    "        for name, weight, _\n",
    "        in chunks\n",
    "    }\n",
    "    \n",
    "    for name, _, children in chunks:\n",
    "        if not children:\n",
    "            continue\n",
    "        node = nodes[name]\n",
    "        for child_name in children.split(', '):\n",
    "            nodes[child_name].add_parent(node)\n",
    "\n",
    "    # We can use any node here.\n",
    "    return node.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"\"\"\n",
    "pbga (66)\n",
    "xhth (57)\n",
    "ebii (61)\n",
    "havc (66)\n",
    "ktlj (57)\n",
    "fwft (72) -> ktlj, cntj, xhth\n",
    "qoyq (66)\n",
    "padx (45) -> pbga, havc, qoyq\n",
    "tknk (41) -> ugml, padx, fwft\n",
    "jptl (61)\n",
    "ugml (68) -> gyxo, ebii, jptl\n",
    "gyxo (61)\n",
    "cntj (57)\n",
    "\"\"\"\n",
    "\n",
    "test_root = parse_input(test_input)\n",
    "assert test_root.name == 'tknk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = parse_input(Input(7).read())\n",
    "root.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second part I needed to find the node lowest in the tree that has a different total weight than it's siblings and calculate what the weight _should_ be. As we know there's only a single node that's the problem, from the root we can identify the node that's incorrect and focus on that subtree until it's no longer incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_total_weights(node):\n",
    "    while True:\n",
    "        weights = [\n",
    "            child.total_weight\n",
    "            for child in node.children\n",
    "        ]\n",
    "        if len(set(weights)) == 1:\n",
    "            # No problems, all weights are the same.\n",
    "            # The problematic node was in the previous\n",
    "            # iteration.\n",
    "            break\n",
    "        \n",
    "        # There are two distinct values, take the second\n",
    "        # most common to give us the odd one out.\n",
    "        incorrect_value = Counter(weights).most_common(2)[1][0]\n",
    "        incorrect_index = weights.index(incorrect_value)\n",
    "        node = node.children[incorrect_index]\n",
    "\n",
    "    target_weight = next(node.siblings).total_weight\n",
    "    diff = target_weight - node.total_weight\n",
    "    return node.weight + diff\n",
    "\n",
    "\n",
    "find_total_weights(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 8: I Heard You Like Registers](http://adventofcode.com/2017/day/8)\n",
    "\n",
    "For this puzzle we have to perform a series of conditional operations based on the values of some \"register\". All of python's conditional operations call magic methods under the hood. i.e. `A > B` is transformed to `A.__gt__(b)`. These operators are mapped to functions within the operator module.\n",
    "\n",
    "As we don't know the number of registers that will be referenced, I use a default dict that can grow to whatever's required. The addition of the `__MAX__` flag is for the second part of the question, which wants to know what the largest value seen was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import gt, lt, ge, le, eq, ne\n",
    "\n",
    "def perform_instructions(instructions):\n",
    "    instructions = list(parse_instructions(instructions))\n",
    "    regs =  defaultdict(int)\n",
    "    \n",
    "    for reg, op, amount, test in instructions:\n",
    "        test_reg, test_op, test_val = test\n",
    "        \n",
    "        if not test_op(regs[test_reg], test_val):\n",
    "            # Test failed, skip operation\n",
    "            continue\n",
    "            \n",
    "        if   op == 'inc': regs[reg] += amount\n",
    "        elif op == 'dec': regs[reg] -= amount\n",
    "            \n",
    "        if regs[reg] > regs['__MAX__']:\n",
    "            regs['__MAX__'] = regs[reg]\n",
    "\n",
    "    return regs\n",
    "\n",
    "\n",
    "def parse_instructions(instructions):\n",
    "    op_map = {\n",
    "        '>': gt,\n",
    "        '<': lt,\n",
    "        '>=': ge,\n",
    "        '<=': le,\n",
    "        '==': eq,\n",
    "        '!=': ne\n",
    "    }\n",
    "    for d in re.findall('(\\w+) (\\w+) (-?\\d+) if (\\w+) ([><=!]+) (-?\\d+)', instructions):\n",
    "        reg, op, amount, test_reg, test_op, test = d\n",
    "        yield (\n",
    "            reg, op, int(amount), (test_reg, op_map[test_op], int(test))\n",
    "        )\n",
    "       \n",
    "    \n",
    "max_reg_val = lambda regs: max(\n",
    "    val\n",
    "    for key, val in regs.items()\n",
    "    if key != '__MAX__'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instructions = \"\"\"\n",
    "b inc 5 if a > 1\n",
    "a inc 1 if b < 5\n",
    "c dec -10 if a >= 1\n",
    "c inc -20 if c == 10\n",
    "\"\"\"\n",
    "regs = perform_instructions(test_instructions)\n",
    "assert max_reg_val(regs) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = perform_instructions(Input(8).read())\n",
    "max_reg_val(regs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs['__MAX__']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 9: Stream Processing](http://adventofcode.com/2017/day/9)\n",
    "\n",
    "This problem asks us seperate blocks according to the following rules:\n",
    "\n",
    "* A new group is identified by a `{` character\n",
    "* The most recently opened group is closed by a `}` character\n",
    "* Garbage is identified by a `<` character\n",
    "* Within garbage, all charactesr have no meaning onther than `!` and `>`\n",
    "* Within garbage `!` causes the next character to be ignored\n",
    "* Within garbage `>` identifies the end of the gabage\n",
    "* Each group can contain subgroups\n",
    "\n",
    "I chose to use a stream interface for this problem as we can recursively solve and update our position within the steam without having to parse it. Perhaps a nicer solution would be to parse the input into the tree it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garbage_advance(stream):\n",
    "    garbage = 0\n",
    "    while True:\n",
    "        char = stream.read(1)\n",
    "        if char == '!':\n",
    "            # Ignore the next character\n",
    "            stream.read(1)\n",
    "            continue\n",
    "\n",
    "        if char == '>':\n",
    "            return garbage\n",
    "        garbage += 1\n",
    "\n",
    "\n",
    "def sum_groups(stream, depth=0):\n",
    "    block_total = depth\n",
    "    garbage_total = 0\n",
    "\n",
    "    while True:\n",
    "        char = stream.read(1)\n",
    "        \n",
    "        if not char:\n",
    "            # Reached the end of the input\n",
    "            break\n",
    "            \n",
    "        if char == '<':\n",
    "            # We have garbage, advance to the end\n",
    "            garbage_total += garbage_advance(stream)\n",
    "            continue\n",
    "\n",
    "        if char == '{':\n",
    "            # Start of the next block\n",
    "            sub_block_total, sub_garbage_total = sum_groups(stream, depth + 1)\n",
    "            block_total += sub_block_total \n",
    "            garbage_total += sub_garbage_total\n",
    "\n",
    "        if char == '}':\n",
    "            # End of current block\n",
    "            return block_total, garbage_total\n",
    "    return block_total, garbage_total\n",
    "\n",
    "    \n",
    "assert sum_groups(StringIO('{}'))[0] == 1\n",
    "assert sum_groups(StringIO('{{}, {}}'))[0] == 5\n",
    "assert sum_groups(StringIO('{{{}}}'))[0] == 6\n",
    "assert sum_groups(StringIO('{{<a!>},{<a!>},{<a!>},{<ab>}}'))[0] == 3\n",
    "assert sum_groups(StringIO('{{<!!>},{<!!>},{<!!>},{<!!>}}'))[0] == 9\n",
    "\n",
    "assert garbage_advance(StringIO('>')) == 0\n",
    "assert garbage_advance(StringIO('random characters>')) == 17\n",
    "assert garbage_advance(StringIO('{o\"i!a,<{i<a>')) == 10\n",
    "\n",
    "sum_groups(Input(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 10: Knot Hash](http://adventofcode.com/2017/day/10)\n",
    "\n",
    "For this puzzle we are required to implement a custom hashing function, which is based entirely on flipping the order of a range of nodes in a circularly linked list. To avoid complications when flipping a range that wraps a list, I rotate the list by the offset of the next rotation, reverse the range (as it is now guaranteed not to wrap) and rotate again by the remaining amount, resetting our offset.\n",
    "\n",
    "(This method was updated after unlocking part two for the inclusion of rounds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knot_hash_round(seq, lengths):\n",
    "    skip_size = 0\n",
    "    pos = 0\n",
    "\n",
    "    for length in lengths:\n",
    "        # partially rotate the list\n",
    "        seq = seq[pos:] + seq[:pos]\n",
    "\n",
    "        # perform the reversal\n",
    "        seq[:length] = seq[:length][::-1]\n",
    "\n",
    "        # complete the rotation\n",
    "        seq = seq[len(seq) - pos:] + seq[:len(seq) - pos]\n",
    "\n",
    "        # Update state\n",
    "        pos += length + skip_size\n",
    "        pos = pos % len(seq)\n",
    "        skip_size += 1\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = list(range(5))\n",
    "res = knot_hash_round(test_input, [3, 4, 1, 5])\n",
    "assert(res[0] * res[1]) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"199,0,255,136,174,254,227,16,51,85,1,2,22,17,7,192\"\n",
    "lengths = map(int, data.split(','))\n",
    "seq = list(range(256))\n",
    "res = knot_hash_round(seq, lengths)\n",
    "print(res[0] * res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part two has quite drastic changes. \n",
    "\n",
    "1. Perform 64 rounds, maintaing state\n",
    "* Input is no longer a CSV, use character ordinal value instaed\n",
    "* Add a trailer of [17, 31, 73, 47, 23] to the lengths\n",
    "* Reduce results to 16 integers by XORing in blocks of 16\n",
    "* Translate resulting integers into a hexidecimal digest\n",
    "\n",
    "To perform the 64 rounds I create a generator that repeats the lengths 64 times. This means we don't need to modify our previous code and the state is automatically preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import chain, repeat\n",
    "from operator import xor\n",
    "\n",
    "def knot_hash(string):\n",
    "    lengths = list(map(ord, string))\n",
    "    seq = list(range(256))\n",
    "    trailer = [17, 31, 73, 47, 23]\n",
    "    lengths.extend(trailer)\n",
    "    # Expand the lengths to represent each round\n",
    "    lengths = chain(*repeat(lengths, 64))\n",
    "\n",
    "    sparse = knot_hash_round(seq, lengths)\n",
    "    dense = [\n",
    "        reduce(xor, chunk)\n",
    "        for chunk in chunks(sparse, 16)\n",
    "    ]\n",
    "    return cat(\n",
    "        '{0:0{1}x}'.format(c, 2) for c in dense\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot_hash(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 11: Hex Ed](http://adventofcode.com/2017/day/11)\n",
    "\n",
    "I've never worked with hexagonal grids before, so this was quite a learning experience for me. Thankfully I found [this](https://www.redblobgames.com/grids/hexagons/), which contains a beautiful breakdown of the various techniques that can be used when working with them.\n",
    "\n",
    "A hexagonal grid can be mapped to cartesian coordinates in a number of ways. Perhaps the hardest to comprehend yet the most useful for us is using cube coordinates. The article above lists in detail how a hexagon can be represented as a slice of a three-dimentional cube. Each face re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = {\n",
    "    'nw': (-1, 1, 0),\n",
    "    'n': (0, 1, -1),\n",
    "    'ne': (1, 0, -1),\n",
    "    'sw': (-1, 0, 1),\n",
    "    's': (0, -1, 1),\n",
    "    'se': (1, -1, 0)\n",
    "}\n",
    "\n",
    "\n",
    "def hex_manhattan_distance(point1, point2=(0, 0, 0)):\n",
    "    return manhattan_distance(point1, point2) // 2\n",
    "\n",
    "\n",
    "def follow_path(path):\n",
    "    origin = (0, 0, 0)\n",
    "    x, y, z = origin\n",
    "    max_dist = 0\n",
    "    for step in path.split(','):\n",
    "        dx, dy, dz = deltas[step]\n",
    "        x += dx\n",
    "        y += dy\n",
    "        z += dz\n",
    "\n",
    "        yield (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Input(11).read().strip()\n",
    "points = follow_path(Input(11).read().strip())\n",
    "hex_manhattan_distance(last(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = follow_path(data)\n",
    "max(map(hex_manhattan_distance, points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 12: Digital Plumber](https://adventofcode.com/2017/day/12)\n",
    "\n",
    "Today we're required to build a bidirectional graphs. We're supplied list of nodes of the form:\n",
    "\n",
    "```\n",
    "    12 <-> 34, 56, 78\n",
    "```\n",
    "\n",
    "Which reads, `node 12 is connected to node 34, 56 and 78`. These nodes are in no particular order, so we can't know before building the graphs how many we'll end up with (the last node could connect all of them together). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(data):\n",
    "    graph = defaultdict(set)\n",
    "    for node, connected in re.findall('(\\d+) <-> ([\\d, ]+)', data):\n",
    "        connected = connected.split(', ')\n",
    "        for dest in connected:\n",
    "            graph[node].add(dest)\n",
    "            graph[dest].add(node)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def count_connected_to_zero(graph):\n",
    "    groups = connected_nodes(graph)\n",
    "    for group in groups:\n",
    "        if '0' in group:\n",
    "            return len(group)\n",
    "\n",
    "\n",
    "def connected_nodes(graph):\n",
    "    groups = []\n",
    "    processed = set()\n",
    "\n",
    "    for node in graph.keys():\n",
    "        if node in processed:\n",
    "            # Seen before, skip\n",
    "            continue\n",
    "\n",
    "        # Follow all new connections\n",
    "        group = set()\n",
    "        to_investigate = [node, ]\n",
    "        while to_investigate:\n",
    "            node = to_investigate.pop() \n",
    "            if node in group:\n",
    "                continue\n",
    "\n",
    "            to_investigate.extend(graph[node])\n",
    "\n",
    "            group.add(node)\n",
    "            processed.add(node)\n",
    "            \n",
    "        groups.append(group)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"\"\"\n",
    "0 <-> 2\n",
    "1 <-> 1\n",
    "2 <-> 0, 3, 4\n",
    "3 <-> 2, 4\n",
    "4 <-> 2, 3, 6\n",
    "5 <-> 6\n",
    "6 <-> 4, 5\n",
    "\"\"\"\n",
    "\n",
    "test_graph = build_graph(test_input)\n",
    "assert(count_connected_to_zero(test_graph)) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_graph(Input(12).read())\n",
    "count_connected_to_zero(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(connected_nodes(test_graph))) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(connected_nodes(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Day 13: Packet Scanners](https://adventofcode.com/2017/day/13)\n",
    "\n",
    "Today we're required to infiltrate a firewall patrolled by security scanners. Each security scanner works at a distinct layer within the wall and walks back and forth along a line of a given depth. We pass through at depth 0, if the the bot is at this depth as we are passing through we're caught.\n",
    "\n",
    "So, if each bot is walking a line of depth `d`, then there are `2d - 2` locations it moves between (the ends are only hit once per cycle). So at a given step in the cycle the bot will be at position `(2d - 2) % step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_firewall(data):\n",
    "    \"\"\"Parse input and translate depths to number of locations.\"\"\"\n",
    "    firewall = defaultdict(int)\n",
    "    \n",
    "    for layer, depth in re.findall('(\\d+): (\\d+)', data):\n",
    "        depth = int(depth)\n",
    "        firewall[int(layer)] = 2 * depth - 2\n",
    "    return firewall\n",
    "\n",
    "\n",
    "def walk_firewall(firewall, delay=0):\n",
    "    length = max(firewall.keys())\n",
    "    \n",
    "    for step in range(length + 1):\n",
    "        depth = firewall[step]\n",
    "        \n",
    "        if depth > 0:\n",
    "            iteration = step + delay\n",
    "            bot_position = iteration % depth\n",
    "            \n",
    "            if bot_position == 0:\n",
    "                cost = step * (depth + 2) // 2\n",
    "                yield cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"\"\"\n",
    "0: 3\n",
    "1: 2\n",
    "4: 4\n",
    "6: 4\n",
    "\"\"\"\n",
    "test_firewall = build_firewall(test_input)\n",
    "assert sum(walk_firewall(test_firewall)) == 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firewall = build_firewall(Input(13).read())\n",
    "sum(walk_firewall2(firewall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_non_hit(firewall):\n",
    "    for n in count(0):\n",
    "        for cost in walk_firewall(firewall, n):\n",
    "            # We were caught, so we can discard this value\n",
    "            break\n",
    "        else:\n",
    "            return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert first_non_hit(test_firewall) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% time first_non_hit(firewall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED = '1'\n",
    "\n",
    "\n",
    "def to_binary(val):\n",
    "    res = cat(\n",
    "        bin(int(c, 16))[2:].zfill(4)\n",
    "        for c in val\n",
    "    ).ljust(32, '0')\n",
    "    return res\n",
    "    \n",
    "    \n",
    "def to_grid(key):\n",
    "    rows = []\n",
    "    for n in range(128):\n",
    "        hash = knot_hash('{}-{}'.format(key, n))\n",
    "        rows.append(to_binary(hash))\n",
    "    return rows\n",
    "        \n",
    "\n",
    "assert to_binary('a0c2017') == '10100000110000100000000101110000'\n",
    "test_grid = to_grid('flqrgnkx')\n",
    "grid = to_grid('amgozmfv')\n",
    "\n",
    "# Find the total number of used values\n",
    "sum(map(lambda row: Counter(row)[USED], grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_regions(grid):\n",
    "    graph = defaultdict(list)\n",
    "    for x in range(128):\n",
    "        for y in range(128):\n",
    "            if grid[x][y] != USED:\n",
    "                # Empty location, don't care about it.\n",
    "                continue\n",
    "\n",
    "            # Add initial region, each node is connected\n",
    "            # to itself\n",
    "            graph[(x, y)].append((x, y))\n",
    "            \n",
    "            # As we're iterating over a grid, we only need\n",
    "            # to check N and E neighbours as others will\n",
    "            # have already been seen\n",
    "            to_check = [(x + 1, y), (x, y + 1)]\n",
    "            for x2, y2 in to_check:\n",
    "                off_grid = x2 == 128 or y2 == 128\n",
    "                if off_grid:\n",
    "                    # Invalid location, ignore\n",
    "                    continue\n",
    "\n",
    "                if grid[x2][y2] == USED:\n",
    "                    graph[(x, y)].append((x2, y2))\n",
    "                    graph[(x2, y2)].append((x, y))\n",
    "\n",
    "    connected = connected_nodes(graph)\n",
    "    return connected\n",
    "\n",
    "\n",
    "assert len(find_regions(test_grid)) == 1242\n",
    "len(find_regions(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed, factor, rule=1):\n",
    "    prev = seed\n",
    "    val = seed\n",
    "    \n",
    "    while True:\n",
    "        prev = (prev * factor) % 2147483647\n",
    "\n",
    "        if prev % rule == 0:\n",
    "            yield prev\n",
    "\n",
    "\n",
    "def gen_pairs(seed_a, seed_b):\n",
    "    yield from zip(\n",
    "        build_generator(seed_a, 16807),\n",
    "        build_generator(seed_b, 48271)\n",
    "    )\n",
    "\n",
    "\n",
    "def judge(pairs, limit):\n",
    "    pairs = islice(pairs, 0, limit)\n",
    "    trailing_bits = lambda n: n & (2 ** 16 - 1)\n",
    "    return sum(\n",
    "        trailing_bits(a) == trailing_bits(b)\n",
    "        for n, (a, b) in enumerate(pairs)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = gen_pairs(65, 8921)\n",
    "# print(judge(test_gen, 5))\n",
    "# assert judge(test_gen, 5) == 1\n",
    "assert judge(test_gen, int(4e7)) == 588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator A starts with 516\n",
    "# Generator B starts with 190\n",
    "gen = gen_pairs(516, 190)\n",
    "judge(gen, int(4e7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gen_pairs(516, 190)\n",
    "judge(gen, int(4e7))\n",
    "%lprun -f build_generator judge(gen, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pairs(seed_a, seed_b):\n",
    "    while True:\n",
    "        yield from zip(\n",
    "            build_generator(seed_a, 16807, 4),\n",
    "            build_generator(seed_b, 48271, 8)\n",
    "        )\n",
    "\n",
    "gen = gen_pairs(516, 190)\n",
    "build_generator judge(gen, int(5e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(data):\n",
    "    moves = []\n",
    "    for chunk in data.split(','):\n",
    "        op = chunk[0]\n",
    "        if op == 's':\n",
    "            args = [int(chunk[1:])]\n",
    "        elif op == 'x':\n",
    "            args = list(map(int, chunk[1:].split('/')))\n",
    "        elif op == 'p':\n",
    "            args = chunk[1:].split('/')\n",
    "        moves.append((op, args))\n",
    "    return moves\n",
    "            \n",
    "    \n",
    "\n",
    "def follow_dance_moves(programs, moves):    \n",
    "    for op, args in moves:\n",
    "        if op == 's':\n",
    "            rotation = args[0]\n",
    "            programs = programs[-rotation:] + programs[:-rotation]\n",
    "        elif op == 'x':\n",
    "            x, y = args\n",
    "            programs[x], programs[y] = programs[y], programs[x]\n",
    "        elif op == 'p':\n",
    "            a, b = args\n",
    "            x, y = programs.index(a), programs.index(b)\n",
    "            programs[x], programs[y] = programs[y], programs[x]\n",
    "    return programs\n",
    "\n",
    "\n",
    "test_moves = parse_input('s1,x3/4,pe/b')\n",
    "assert cat(follow_dance_moves(list('abcde'), test_moves)) == 'baedc'\n",
    "moves = parse_input(Input(16).read())\n",
    "cat(follow_dance_moves(list('abcdefghijklmnop'), moves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs = list('abcdefghijklmnop')\n",
    "lim = 1000000000\n",
    "\n",
    "positions = []\n",
    "positions.append(cat(programs))\n",
    "for n in range(lim):\n",
    "    programs = follow_dance_moves(programs, moves)\n",
    "    p = cat(programs)\n",
    "    if p in positions:\n",
    "        break\n",
    "    positions.append(p)\n",
    "    \n",
    "# We have a repeating index, as such just we can find the end position easily\n",
    "rem = lim % len(positions)\n",
    "positions[rem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spinlock(step_size):\n",
    "    state = [0]\n",
    "    pos = 0\n",
    "    for step in count(1):\n",
    "        pos = (pos + step_size) % len(state) + 1\n",
    "        state.insert(pos, step)\n",
    "        yield state, pos\n",
    "\n",
    "def spin2017(step_size):\n",
    "    items = head(\n",
    "        2017,\n",
    "        spinlock(step_size),\n",
    "    )\n",
    "    state, pos = list(items)[-1]\n",
    "    print(pos)\n",
    "    return state[pos + 1]\n",
    "    \n",
    "\n",
    "# gen = spinlock(3)\n",
    "# assert next(gen)[0] == [0, 1]\n",
    "# assert next(gen)[0] == [0, 2, 1]\n",
    "# assert spin2017(3) == 638\n",
    "\n",
    "spin2017(316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_val_at_index(step_size, index=1):\n",
    "    state_length = 1\n",
    "    pos = 0\n",
    "    val = None\n",
    "    for step in count(1):\n",
    "        pos = (pos + step_size) % step + 1\n",
    "        if pos == index:\n",
    "            val = step\n",
    "        state_length += 1\n",
    "        yield val\n",
    "\n",
    "%time nth_item(50000000, track_val_at_index(316))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instructions(data):\n",
    "    return re.findall('(\\w+) (\\w+)(?: ([\\-\\w]+))?', data)\n",
    "\n",
    "\n",
    "def follow_instructions(instructions, regs, queue=[]):\n",
    "    \n",
    "    int_or_reg = lambda x: regs[x] if x.isalpha() else int(x)\n",
    "    pos = 0\n",
    "    played = None\n",
    "    \n",
    "    while pos < len(instructions):\n",
    "        instruction, args = instructions[pos][0], instructions[pos][1:]\n",
    "        \n",
    "        if   instruction == 'set': regs[args[0]] = int_or_reg(args[1])\n",
    "        elif instruction == 'add': regs[args[0]] += int_or_reg(args[1])\n",
    "        elif instruction == 'snd': yield 'snd', int_or_reg(args[0])\n",
    "        elif instruction == 'mul': regs[args[0]] *= int_or_reg(args[1])\n",
    "        elif instruction == 'mod': regs[args[0]] %= int_or_reg(args[1])\n",
    "        elif instruction == 'rcv': \n",
    "            while len(queue) == 0:\n",
    "                yield ('rcv', )\n",
    "            regs[args[0]] = queue.popleft()\n",
    "        elif instruction == 'jgz':\n",
    "            should_jump = int_or_reg(args[0]) > 0\n",
    "            if should_jump:\n",
    "                pos += int_or_reg(args[1])\n",
    "                continue\n",
    "                \n",
    "        pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_snt_at_first_rcv(instructions):\n",
    "    gen = follow_instructions(instructions, defaultdict(int))\n",
    "\n",
    "    sent = 0\n",
    "    for op in gen:\n",
    "        if op[0] == 'snd':\n",
    "            sent = op[1]\n",
    "        else:\n",
    "            break\n",
    "    return sent\n",
    "\n",
    "test_instructions = \"\"\"\n",
    "set a 1\n",
    "add a 2\n",
    "mul a a\n",
    "mod a 5\n",
    "snd a\n",
    "set a 0\n",
    "rcv a\n",
    "jgz a -1\n",
    "set a 1\n",
    "jgz a -2\n",
    "\"\"\"\n",
    "last_snt_at_first_rcv(parse_instructions(test_instructions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = parse_instructions(Input(18).read())\n",
    "last_snt_at_first_rcv(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_duet(instructions):\n",
    "    regs_a = defaultdict(int)\n",
    "    regs_a['p'] = 0\n",
    "    queue_a = deque()\n",
    "\n",
    "    regs_b = defaultdict(int)\n",
    "    regs_b['p'] = 1\n",
    "    queue_b = deque()\n",
    "    \n",
    "    gen_a = follow_instructions(instructions, regs_a, queue_a)\n",
    "    gen_b = follow_instructions(instructions, regs_b, queue_b)\n",
    "    \n",
    "    c = 0\n",
    "    \n",
    "    while True:\n",
    "        val_a = next(gen_a)\n",
    "        val_b = next(gen_b)\n",
    "        \n",
    "        if val_a[0] == val_b[0] and val_a[0] == 'rcv':\n",
    "            # deadlock\n",
    "            break\n",
    "\n",
    "        if val_a[0] == 'snd':\n",
    "            queue_b.append(val_a[1])\n",
    "            \n",
    "        if val_b[0] == 'snd':\n",
    "            queue_a.append(val_b[1])\n",
    "            c += 1\n",
    "            \n",
    "    return c\n",
    "\n",
    "test_instructions = parse_instructions(\"\"\"\n",
    "snd 1\n",
    "snd 2\n",
    "snd p\n",
    "rcv a\n",
    "rcv b\n",
    "rcv c\n",
    "rcv d\n",
    "\"\"\")\n",
    "assert perform_duet(test_instructions) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_duet(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 19\n",
    "\n",
    "This solution works but gets caught in a loop and needs work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTIONS = [\n",
    "    (0, 1),\n",
    "    (0, -1),\n",
    "    (1, 0),\n",
    "    (-1, 0),\n",
    "]\n",
    "import string\n",
    "\n",
    "def follow_path(grid):\n",
    "    y = 0\n",
    "    x = grid[0].index('|')\n",
    "    direction = (0, 1)\n",
    "    chars = []\n",
    "    \n",
    "    d = 0\n",
    "    steps = 0\n",
    "    while True:\n",
    "        dx, dy = direction\n",
    "        x += dx\n",
    "        y += dy\n",
    "        \n",
    "        if (x < 0 or y < 0):\n",
    "            # Walked off the grid, we're done\n",
    "            break\n",
    "            \n",
    "        steps += 1\n",
    "\n",
    "        if char == '+':\n",
    "            # Only change if there's no other option\n",
    "            try:\n",
    "                next_char = grid[y + dy][x + dx]\n",
    "                should_change_dir = next_char == ' '\n",
    "            except IndexError:\n",
    "                should_change_dir = True\n",
    "            \n",
    "            if should_change_dir:\n",
    "                # Changing direction\n",
    "                for dx2, dy2 in DIRECTIONS:\n",
    "                    if abs(dx2) == abs(dx):\n",
    "                        # we have to change direction\n",
    "                        continue\n",
    "                    try:\n",
    "                        next_char = grid[y + dy2][x + dx2]\n",
    "                        if next_char == ' ':\n",
    "                            # We have to stay on the path\n",
    "                            continue\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "\n",
    "                    if abs(dy2) and next_char not in '|+' + string.ascii_uppercase:\n",
    "                        continue\n",
    "                    elif abs(dx2) and next_char not in '-+' + string.ascii_uppercase:\n",
    "                        continue\n",
    "                    direction = (dx2, dy2)\n",
    "                    d += 1\n",
    "                    break\n",
    "                else:\n",
    "                    print('no change')\n",
    "        \n",
    "        elif char not in '-| ':\n",
    "            chars.append(char)\n",
    "            print (cat(chars), steps)\n",
    "    print('direction changes', d)\n",
    "    return cat(chars)\n",
    "\n",
    "\n",
    "\n",
    "test_grid = \"\"\"     |          \n",
    "     |  +--+    \n",
    "     A  |  C    \n",
    " F---|----E|--+ \n",
    "     |  |  |  D \n",
    "     +B-+  +--+ \n",
    "\"\"\".split('\\n')\n",
    "\n",
    "assert follow_path(test_grid) == 'ABCDEF'\n",
    "print(Counter(Input(19).read()))\n",
    "follow_path(Input(19).read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 20\n",
    "\n",
    "We're given a set of particles, their position, velocity and accelleration. We need to find the particle that stays closest to the origin in the long term. This means that over a period of time, we need to know which ones are accelerating away from the origin the fastest, as eventually all the others will have moved futher away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(data):\n",
    "    vector = r'(-?\\d+,-?\\d+,-?\\d+)'\n",
    "    results = re.findall(r'p=<{vector}>, v=<{vector}>, a=<{vector}>'.format(vector=vector), data)\n",
    "    to_vector = lambda x: np.array([int(y) for y in x.split(',')])\n",
    "    data = tuple(\n",
    "        tuple(to_vector(c) for c in chunks)\n",
    "        for idx, chunks in enumerate(results)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def perform_update(state):\n",
    "    return tuple(\n",
    "        (p + v + a, v + a, a)\n",
    "        for (p, v, a) in state\n",
    "    )\n",
    "\n",
    "\n",
    "def tick(state, remove_collisions=False):\n",
    "    while True:\n",
    "        yield state\n",
    "        state = perform_update(state)\n",
    "        \n",
    "        if remove_collisions:\n",
    "            counts = Counter([tuple(pos) for (pos, _, _) in state])\n",
    "            state = tuple(\n",
    "                (pos, vec, acc)\n",
    "                for pos, vec, acc in state\n",
    "                if counts[tuple(pos)] == 1\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "def closest_to_zero(state):\n",
    "    closest_particle = 0\n",
    "    dist = lambda p: manhattan_distance((0, 0, 0), p)\n",
    "    \n",
    "    accellerations = [\n",
    "        sum(map(abs, acc))\n",
    "        for (_, _, acc) in state\n",
    "    ]\n",
    "    \n",
    "    slowest = min(accellerations)\n",
    "    slowest_particles = (\n",
    "        particle\n",
    "        for idx, particle in enumerate(state)\n",
    "        if accellerations[idx] == slowest\n",
    "    )\n",
    "    closest_slow_particle = min(\n",
    "        slowest_particles,\n",
    "        key=lambda particle: dist(particle[0])\n",
    "    )\n",
    "    # Now we have the slowest particle, find its index.\n",
    "    for idx, particle in enumerate(state):\n",
    "        if np.allclose(particle, closest_slow_particle):\n",
    "            return idx\n",
    "\n",
    "        \n",
    "test_data = \"\"\"\n",
    "p=<3,0,0>, v=<2,0,0>, a=<-1,0,0>\n",
    "p=<4,0,0>, v=<0,0,0>, a=<-2,0,0>\n",
    "\"\"\"\n",
    "state = parse_input(test_data)\n",
    "state = perform_update(state)\n",
    "assert list(state[0][0]) == [4, 0, 0]\n",
    "assert closest_to_zero(state) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = parse_input(Input(20).read())\n",
    "closest_to_zero(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def no_collisions(state):\n",
    "    for i, state in enumerate(tick(state, True)):\n",
    "        if i > 100:\n",
    "            break\n",
    "    return len(state)          \n",
    "\n",
    "no_collisions(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_array(data):\n",
    "    return np.array(\n",
    "        [\n",
    "            [0 if char == '.' else 1 for char in row]\n",
    "            for row in data.split('/')\n",
    "        ],\n",
    "        dtype=int\n",
    "    )\n",
    "\n",
    "\n",
    "def to_str(arr):\n",
    "    return '\\n'.join(\n",
    "        cat('.#'[int(val)] for val in row)\n",
    "        for row in arr\n",
    "    )\n",
    "\n",
    "\n",
    "def rotations(arr):\n",
    "    for dist in range(4):\n",
    "        yield np.rot90(arr, dist)\n",
    "        \n",
    "        \n",
    "def flips(arr):\n",
    "    yield arr\n",
    "    yield np.flip(arr, 0)\n",
    "    yield np.flip(arr, 1)\n",
    "\n",
    "    \n",
    "def parse_input(data):\n",
    "    mapping = {}\n",
    "    for lhs, rhs in re.findall(r'(.*) => (.*)', data):\n",
    "        rhs_array = to_array(rhs)\n",
    "        lhs_array = to_array(lhs)\n",
    "        \n",
    "        for flip in flips(lhs_array):\n",
    "            for rot in rotations(flip):\n",
    "                frozen_array = tuple(map(tuple, rot))\n",
    "                mapping[frozen_array] = rhs_array\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def chunkify_array(arr, size):\n",
    "    return [\n",
    "        arr[i:i+size, j:j+size] for j in range(0, len(arr), size)\n",
    "        for i in range(0, len(arr), size)\n",
    "    ]\n",
    "\n",
    "\n",
    "def enhance(arr, mapping):\n",
    "    if len(arr) % 2 == 0:\n",
    "        size = len(arr) // 2\n",
    "        new_size = size * 3\n",
    "        chunks = chunkify_array(arr, 2)\n",
    "        \n",
    "    elif len(arr) % 3 == 0:\n",
    "        size = len(arr) // 3\n",
    "        new_size = size * 4\n",
    "        chunks = chunkify_array(arr, 3)\n",
    "        \n",
    "    # Now we perform the mapping on each section, and rejoin\n",
    "    # to a single array.\n",
    "    out = np.zeros((new_size, new_size), dtype=int)\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        frozen_chunk = tuple(map(tuple, chunk))\n",
    "        mapped = mapping[frozen_chunk]\n",
    "        i = (idx * len(mapped)) % new_size\n",
    "        j = (idx * len(mapped)) // new_size * len(mapped)\n",
    "        out[i:i+len(mapped), j:j+len(mapped)] = mapped\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "def run(mapping, iterations):\n",
    "    start = np.array(\n",
    "    object=(\n",
    "            (0, 1, 0),\n",
    "            (0, 0, 1),\n",
    "            (1, 1, 1),\n",
    "        )\n",
    "    )\n",
    "    arr = start\n",
    "    for _ in range(iterations):\n",
    "        arr = enhance(arr, mapping)\n",
    "        yield arr\n",
    "\n",
    "        \n",
    "def count_turned_on(mapping, iterations):\n",
    "    result = last(run(mapping, iterations))\n",
    "    return sum(sum(result))             \n",
    "\n",
    "\n",
    "test_input = \"\"\"\n",
    "../.# => ##./#../...\n",
    ".#./..#/### => #..#/..../..../#..#\n",
    "\"\"\"\n",
    "\n",
    "mapping = parse_input(test_input)\n",
    "assert count_turned_on(mapping, 2) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = parse_input(Input(21).read())\n",
    "count_turned_on(mapping, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.36 s, sys: 71.3 ms, total: 5.43 s\n",
      "Wall time: 5.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1911767"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% time count_turned_on(mapping, 18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
